2010 univ dept part m l l e t m achine learning languag e toolkit 1 0 information see ` l e n e semi supervise r f transducer semi supervise constraint g e constraint type feature vector type feature vector type log run dynamic programming algorithm mann mc callum 08 computing gradient generalize expectation constraint consider single label linear chain r f see generalize expectation criterion semi supervise learning conditional random field gideon mann mc callum l 2008 gdruck n o t e g e lattice compute gradient constraint simultaneously gregory druck gaurav chandalia gideon mann g e lattice input length + 1 lattice length model transducer transducer f t num dynamic programming lattice lattice node lattice cache dot produce between violation constraint feature log dot cache fv input feature vector gamma marginal over single xi marginal over pair transducer transducer reverse tran index destination reverse tran index transition index destination gradient gradient increment constraint constraint check run debug test verify correctness much slow g e lattice feature vector fv gamma xi transducer transducer reverse tran reverse tran index r f factor gradient g e constraint constraint check gradient lattice length fv size + 1 transducer transducer num transducer num lattice lattice lattice node lattice length num ip 0 ip lattice length ++ip 0 num ++a lattice ip lattice node dot cache log lattice length num num t o o maybe cached? list constraint look v two g e constraint constraints1 g e constraint g e constraint constraints2 g e constraint g e constraint constraint constraint constraint constraint constraints1 add constraint constraints2 add constraint r f crf r f transducer dot ex run forward crf constraints1 constraints2 gamma xi reverse tran fv run backward crf gamma xi reverse tran reverse tran index fv dot ex gradient check constraint gamma xi fv run forward pas dynamic programming algorithm crf r f constraints1 constraint consider constraints2 constraint consider two gamma marginal over single xi marginal over pair reverse tran index destination fv input feature vector run forward r f crf g e constraint constraints1 g e constraint constraints2 gamma xi reverse tran feature vector fv dot ex 0 log value cache log num log nu alpha log transducer m p o l e w e g h t log temp log transducer m p o l e w e g h t ip 0 ip lattice length 1 ++ip feature vector fv fv get ip speed thing up giving constraint opportunity cache constrain input feature appear feature vector g e constraint constraint constraints1 constraint pre process fv g e constraint constraint constraints2 constraint pre process fv val compute num prev 0 prev num prev++ nu alpha transducer m p o l e w e g h t ip 0 prev prev reverse tran prev calculate once \sum y 1 w y 1 y ppi 0 ppi prev prev length ppi++ nu alpha plus equal lattice ip 1 prev prev ppi alpha prev na n nu alpha log val r f prev r f crf get prev lattice node node lattice ip prev xi xi ip prev gamma gamma ip prev ci 0 ci prev num destination ci++ curr prev get destination ci get index dot 0 g e constraint constraint constraints2 dot + constraint get composite constraint feature value fv ip prev curr recomput constraint feature label time val compute curr o val 0 g e constraint constraint constraints1 o val + constraint get composite constraint feature value fv ip prev curr o val 0 dot ex + math gamma ip+1 curr o val value cache curr log math log o val o val 0 dot ex + math gamma ip+1 curr o val value cache curr log math log o val value cache curr val compute curr combine two constraint feature value dot 0 value cache curr dot cache ip prev curr dot 0 value cache curr dot cache ip prev curr value cache curr dot ex + math xi curr dot dot 0 dot cache ip prev curr log math log dot dot cache ip prev curr log math log dot value cache curr dot cache ip prev curr plus equal value cache curr update dynamic programming table dot cache ip prev curr temp xi curr temp time equal dot cache ip prev curr node alpha curr plus equal temp gamma transducer m p o l e w e g h t node alpha curr log transducer m p o l e w e g h t temp xi curr gamma temp time equal nu alpha node alpha curr plus equal temp na n node alpha curr log val xi + xi curr + gamma + gamma + constraint feature + dot cache ip prev curr + nu apha + nu alpha + dot + dot dot ex run backward pas dynamic programming algorithm crf r f gamma marginal over single xi marginal over pair reverse tran index destination reverse tran index transition index destination fv input feature vector dot ex expectation constraint feature dot violation gradient gradient increment run backward r f crf gamma xi reverse tran reverse tran index feature vector fv dot ex r f factor gradient log nu beta log transducer m p o l e w e g h t log dot log transducer m p o l e w e g h t log temp log transducer m p o l e w e g h t log temp2 log transducer m p o l e w e g h t log next dot ip lattice length 2 ip 0 ip curr 0 curr num ++curr nu beta transducer m p o l e w e g h t dot transducer m p o l e w e g h t calculate once \sum y i+1 w y y+i r f curr r f crf get curr ni 0 ni curr num destination ni++ next curr get destination ni get index nu beta plus equal lattice ip+1 curr beta next na n nu beta log val next dot dot cache ip+1 curr next next dot xi xi ip+1 curr next temp xi temp time equal next dot dot plus equal temp gamma gamma ip+1 curr prev reverse tran curr pi 0 pi prev length pi++ prev prev pi r f crf r f crf get prev lattice node node lattice ip prev xi xi ip prev curr gamma transducer m p o l e w e g h t node beta curr log transducer m p o l e w e g h t constraint feature value cache forward pas temp dot log val dot sign temp plus equal nu beta temp2 xi gamma temp time equal temp2 node beta curr plus equal temp na n node beta curr log val xi + xi + gamma + gamma + xi + xi + log indicator feat + dot cache ip curr compute update gradient tran prob math xi cov first term node alpha curr + node beta curr cov first term tran prob dot ex nwi crf get weight name reverse tran index curr pi length weight index wi 0 wi nwi wi++ weight index r f transducer get weight index crf get weight name reverse tran index curr pi wi gradient weight weight index plus equal sparse fv get ip gradient weight weight index + verifie correctness lattice computation check g e constraint constraint gamma xi feature vector fv sum marginal probability ex1 0 0 ip 0 ip lattice length 1 ++ip si1 0 si1 num si1++ si2 0 si2 num si2++ dot 0 g e constraint constraint constraint dot + constraint get composite constraint feature value fv get ip ip si1 si2 prob math xi ip si1 si2 ex1 + prob dot ex2 0 0 ip 0 ip lattice length 1 ++ip ex3 0 0 s1 0 s1 num ++s1 lattice node node lattice ip s1 s2 0 s2 num ++s2 ex3 + node alpha s2 + node beta s2 equal marginal prob ex1 ex3 1e 6 ex1 + + ex3 ex2 + ex3 ex2 ex2 lattice length 1 equal marginal prob ex1 ex2 1e 6 ex1 + + ex2 log get alpha ip s1 s2 lattice ip s1 alpha s2 log get beta ip s1 s2 lattice ip s1 beta s2 contain forward backward vector correspod input position index lattice node ip input position vector since node we need keep track alpha beta value ip+1 log alpha log beta lattice node alpha log num beta log num si 0 si num ++si alpha si log transducer m p o l e w e g h t beta si log transducer m p o l e w e g h t 