2003 univ dept part m l l e t m achine learning languag e toolkit 1 0 information see ` l e n e learning type assignment type assignment iterator type factor type variable optimize optimizable type instance type instance type sparse vector logger cache optimizable io output stream io o io print stream io serializable bit iterator logging logger create mar 15 2005 h r e f $ cliquewise r f trainer v 1 1 2007 10 22 21 37 40 $ piecewise r f trainer acrf trainer logger logger logger get logger piecewise r f trainer get name print gradient optimizable gradient value optimizable r f acrf instance training maxable acrf training maxable cache optimizable gradient serializable r f acrf instance train r f template template r f template fix tmpl bit infinite value num e f u l t g u n p r o r v r n e 10 0 get gaussian prior variance gaussian prior variance gaussian prior variance gaussian prior variance gaussian prior variance gaussian prior variance gaussian prior variance e f u l t g u n p r o r v r n e vector contain count feature observe training map clique template feature count sparse vector constraint vector contain expect value over label feature see training training label sparse vector expectation sparse vector constraint sparse vector expectation init weight instance training tidx 0 tidx template length tidx++ num + template tidx init weight training initialize constraint expectation same dimension weight zero init constraint expectation first constraint sparse vector template length expectation sparse vector template length tidx 0 tidx template length tidx++ sparse vector template tidx get weight constraint tidx sparse vector clone matrix zero expectation tidx sparse vector clone matrix zero now other constraint sparse vector template length expectation sparse vector template length tidx 0 tidx template length tidx++ r f template tmpl template tidx sparse vector weight tmpl get weight constraint tidx sparse vector weight length expectation tidx sparse vector weight length 0 weight length i++ constraint tidx sparse vector weight clone matrix zero expectation tidx sparse vector weight clone matrix zero expectation 0 they ve be initialize reset expectation tidx 0 tidx expectation length tidx++ expectation tidx 0 0 0 expectation tidx length i++ expectation tidx 0 0 reset constraint tidx 0 tidx constraint length tidx++ constraint tidx 0 0 0 constraint tidx length i++ constraint tidx 0 0 maxable r f acrf instance ilist logger fine initialize optimizable r f acrf acrf template acrf get template fix tmpl acrf get fix template allocate weight constraint expectation train ilist init weight train init constraint expectation num instance train size cache value stale cache gradient stale cache unroll graph unroll graph unroll graph num instance logger info training instance + num instance logger info + num describe prior logger fine computing constraint collect constraint train describe prior logger info gaussian prior variance +gaussian prior variance get num num negate value value because weight value get buf buf length num illegal argument argument + correct dimension idx 0 tidx 0 tidx template length tidx++ r f template tmpl template tidx sparse vector tmpl get weight value get value arraycopy value 0 buf idx value length idx + value length tidx 0 tidx template length tidx++ r f template tmpl template tidx sparse vector weight tmpl get weight assn 0 assn weight length assn++ value weight assn get value arraycopy value 0 buf idx value length idx + value length internal cache value stale cache gradient stale idx 0 tidx 0 tidx template length tidx++ r f template tmpl template tidx sparse vector tmpl get weight value get value arraycopy idx value 0 value length idx + value length tidx 0 tidx template length tidx++ r f template tmpl template tidx sparse vector weight tmpl get weight assn 0 assn weight length assn++ value weight assn get value arraycopy idx value 0 value length idx + value length function unit test get constraint expectation m too lazy deep caller these sparse vector get expectation cnum expectation cnum sparse vector get constraint cnum constraint cnum print weight print buf num get buf len buf length w 0 w len w++ print buf w + compute value retval 0 0 num instance train size start current milli unroll 0 instance value nev total value we can t just sometime skip value because infinite off total value we instance infinite value happen start we t compute value instance first round instance infinite value initialize infinite value infinite value we could initialize bitset slot instance probably cheap taking hit allocate space bit become infinite value bit initialize infinite value clear statistic we about fill reset expectation fill expectation instance 0 num instance i++ retval + compute value instance retval + compute prior current milli logger info r f inference m + start logger info r f unroll m +unroll logger info get value loglikelihood +retval retval incorporate gaussian prior weight we add w^2 2 variance log probability compute prior retval 0 0 prior denom 2 gaussian prior variance tidx 0 tidx template length tidx++ sparse vector weight template tidx get weight j 0 j weight length j++ fnum 0 fnum weight j num location fnum++ w weight j value location fnum weight w tidx j retval + w w prior denom retval compute value instance retval 0 0 instance instance train get compute marginal clique r f unroll graph unroll r f unroll graph instance template fix tmpl unroll num variable 0 0 happen node prune save expect value feature we compute gradient assignment observation unroll get assignment value collect expectation value unroll observation na n value na n instance +i+ +instance get name print debug info unroll illegal value na n r f get value instance +i logger warning value na n r f get value instance +i+ + infinity n e g t v e n f n t y retval + value retval compute gradient penalize log likelihood r f place cache gradient gradient constraint expectation gaussian prior variance compute value gradient grad compute value gradient grad 1 0 compute value gradient grad prior scale index into current element cache gradient gidx 0 first gradient wrt weight tidx 0 tidx template length tidx++ sparse vector these weight template tidx get weight sparse vector these constraint constraint tidx sparse vector these expectation expectation tidx j 0 j these weight num location j++ weight these weight value location j constraint these constraint value location j expectation these expectation value location j print gradient gradient +gidx+ +constraint+ ctr +expectation+ + weight gaussian prior variance + reg feature e f u l t grad gidx++ constraint expectation prior scale weight gaussian prior variance now weight tidx 0 tidx template length tidx++ r f template tmpl template tidx sparse vector weight tmpl get weight 0 weight length i++ sparse vector weight vec weight sparse vector constraint vec constraint tidx sparse vector expectation vec expectation tidx j 0 j weight vec num location j++ w weight vec value location j gradient compute below constraint constraint vec value location j expectation expectation vec value location j parameter infinity external user we gradient 0 because parameter value can nev change anyway mess up future calculation matrix infinite w logger warning infinite weight node index +i+ feature + acrf get input alphabet lookup j gradient 0 0 gradient constraint prior scale w gaussian prior variance expectation print gradient idx weight vec index location j fname acrf get input alphabet lookup idx gradient +gidx+ +constraint+ ctr +expectation+ + w gaussian prior variance + reg feature +fname+ grad gidx++ gradient feature f k compute expect value f k aver possible label sequence instance we these value store collector collector j k get expect value feature clique label assignment j input feature k collect expectation value r f unroll graph unroll assignment observation value 0 0 iterator unroll unroll var iterator next r f unroll var clique r f unroll var next tidx clique get template index tidx 1 factor ptl unroll factor clique log z math log ptl sum assigment clique xxx l o w need sparsifi assignment iterator assn clique assignment iterator 0 assn next marginal math ptl log value assn log z expectation tidx plus equal sparse clique get fv marginal expectation tidx location 1 expectation tidx increment value marginal assn advance i++ value + ptl log value observation log z value collect constraint instance ilist inum 0 inum ilist size inum++ logger fine collecting constraint instance +inum collect constraint instance ilist inum collect constraint instance instance ilist inum instance inst ilist get inum r f unroll graph unroll r f unroll graph inst template iterator unroll unroll var iterator next r f unroll var clique r f unroll var next tidx clique get template index tidx 1 assn clique lookup assignment constraint tidx assn plus equal sparse clique get fv constraint tidx location assn 1 constraint tidx increment value assn 1 0 dump gradient name grad get num get value gradient grad print stream w print stream output stream name 0 num i++ w grad w close o e err could output e print stack trace dump constraint 0 constraint length i++ template +i constraint print expectation 0 expectation length i++ template +i expectation print print debug info r f unroll graph unroll acrf print err assignment assn unroll get assignment iterator unroll unroll var iterator next r f unroll var clique r f unroll var next clique +clique dump assn clique assn clique factor ptl unroll factor clique value +ptl value assn ptl dump assn clique assignment assn r f unroll var clique iterator clique iterator next variable var variable next var+ +assn get var + +assn get var + weight w cnum j infinite w logger warning weight infinite clique +cnum+ assignment +j na n w logger warning weight nan clique +cnum+ assignment +j num batch 0 compute value gradient instance num batch++ collect constraint instance train instance value compute value instance instance value + compute prior train size value get num instance train size get cache gradient grad compute value gradient grad num batch train size reset value gradient reset expectation reset constraint optimizable r f 