2005 univ dept part m l l e t m achine learning languag e toolkit 1 0 information see ` l e n e topic gnu trove t hash map tree iterator zip io format type random latent dirichlet allocation optimize hyperparameter david mimno mc callum deprecate parallel topic model instead us substantially fast structure parallel operation l hyp serializable analogou classify classification topication serializable instance instance l hyp model label topic label topic actually construct model fitting could test document topication instance instance l hyp model label topic instance instance model model topic topic maintainable serialization serial u 1 u r r e n t e r l v e r o n 0 write output stream o write u r r e n t e r l v e r o n write instance write model write topic write topic read input stream o found read instance instance read model l hyp read topic label read topic label read topication training instance topic assignment alphabet alphabet alphabet input label alphabet topic alphabet alphabet topic num topic topic fit num type alpha dirichlet alpha alpha over topic alpha sum beta prior topic multinomial over word beta sum e f u l t e t 0 01 smooth mass 0 0 cache coefficient topic term count 0 beta topic count 0 smooth count 0 instance empirical likelihood calculation instance testing put topic count current document initialize locally below define here garbage collection overhead doc topic count index document index topic index gnu trove t hash map type topic count index feature index topic index topic index topic index dirichlet estimation doc length count histogram document size topic doc count histogram document topic count index topic index position index iteration far 0 num iteration 1000 burnin 20 50 200 save sample interval 5 10 optimize interval 20 50 show topic interval 10 50 word topic 7 output model interval 0 output model filename save interval 0 filename random random format formatt print log likelihood l hyp topic topic topic e f u l t e t l hyp topic alpha sum beta topic alpha sum beta random label alphabet label alphabet num topic label alphabet ret label alphabet 0 num topic i++ ret lookup index topic +i ret l hyp topic alpha sum beta random random label alphabet topic alpha sum beta random l hyp label alphabet topic alphabet alpha sum beta random random topication topic alphabet topic alphabet num topic topic alphabet size alpha sum alpha sum alpha num topic fill alpha alpha sum num topic beta beta random random doc topic count num topic topic num topic formatt format get instance formatt maximum fraction digit 5 err l + num topic + topic alphabet get alphabet alphabet label alphabet get topic alphabet topic alphabet get num topic num topic topication get get count feature topic feature index topic index type topic count feature index get topic index get count topic topic index topic topic index hold instance empirical likelihood calculation testing instance instance testing testing testing num iteration num iteration num iteration num iteration burnin burnin burnin burnin topic interval n show topic interval interval word topic n random seed seed random random seed optimize interval interval optimize interval interval model output interval filename output model interval interval output model filename filename define often save interval save interval iteration filename save iteration suffix save interval filename save interval interval filename filename instance length instance instance feature instance get size can safely call multiple time complain can t handle situation initialize type alphabet alphabet alphabet alphabet alphabet num type alphabet size type topic count t hash map num type fi 0 fi num type fi++ type topic count fi t hash map beta sum beta num type alphabet alphabet illegal argument cannot change alphabet alphabet size num type num type alphabet size t hash map type topic count t hash map num type 0 type topic count length i++ type topic count type topic count type topic count length num type i++ type topic count t hash map t o o k m july 18 why wasn t next line there previously? type topic count type topic count beta sum beta num type nothing change nothing initialize type topic count t hash map type topic count t hash map num type 0 type topic count length i++ type topic count type topic count type topic count length num type i++ type topic count t hash map type topic count type topic count add instance instance training initialize type training get alphabet label topic sequence label instance instance training label topic label topic alphabet instance length instance yet obey last argument work sample topic doc feature instance get topic random r random topic topic get feature 0 topic length i++ topic r next num topic topic sequence add topic add instance training topic sequence add instance instance training label topic initialize type training get alphabet training size topic size 0 training size i++ topication t topication training get topic get add t statistic doc feature feature t instance get label topic t topic pi 0 pi topic get length pi++ topic topic get index position pi type topic count get index position pi adjust put value topic 1 1 topic topic ++ initialize histogram cache value gather statistic size document histogram dirichlet hyperparamet optimization initialize histogram cache value max 0 total 0 seq len doc 0 doc size doc++ feature f feature get doc instance get seq len f get length seq len max max seq len total + seq len initialize smooth sampling bucket smooth mass 0 topic 0 topic num topic topic++ smooth mass + alpha topic beta topic topic + beta sum initialize cache coefficient smooth cache coefficient num topic topic 0 topic num topic topic++ cache coefficient topic alpha topic topic topic + beta sum err max + max err total + total doc length count max + 1 topic doc count num topic max + 1 estimate o estimate num iteration estimate iteration round o start current milli max iteration iteration far + iteration round iteration far max iteration iteration far++ iteration start current milli show topic interval 0 iteration far 0 iteration far % show topic interval 0 print top word word topic testing el empirical likelihood 1000 testing ll model log likelihood mi topic label mutual information ll + + el + + mi save interval 0 iteration far % save interval 0 print filename + + iteration far output model interval 0 iteration % output model interval 0 write output model filename+ +iteration t o o also check we sample work here sample actually obtain yet track iteration far burnin optimize interval 0 iteration far % optimize interval 0 alpha sum dirichlet learn alpha topic doc count doc length count smooth mass 0 0 topic 0 topic num topic topic++ smooth mass + alpha topic beta topic topic + beta sum cache coefficient topic alpha topic topic topic + beta sum clear histogram loop over document corpus topic term count beta topic count smooth count 0 num doc size t o o consider beginning sub sampling? di 0 di num doc di++ feature feature get di instance get label topic label get di topic sample topic doc topic iteration far burnin iteration far % save sample interval 0 elapse milli current milli iteration start elapse milli 1000 print elapse milli + m print elapse milli 1000 + topic term count + + beta topic count + + smooth count iteration far % 10 0 + iteration far + print log likelihood model log likelihood flush second math round current milli start 1000 0 minute second 60 second % 60 hour minute 60 minute % 60 day hour 24 hour % 24 print total day 0 print day print day hour 0 print hour print hour minute 0 print minute print minute print second second clear histogram fill doc length count 0 topic 0 topic topic doc count length topic++ fill topic doc count topic 0 topic assignment already account statistic readjust topic stat topic re sample statistic operate test document feature topic already account statistic readjust topic stat current topic assignment ignore statistic change you want estimate dirichlet alpha document topic multinomial sample round save alpha estimation old sample topic doc feature feature feature topic save alpha estimation readjust topic stat start current milli doc topic topic get feature t hash map current type topic count type old topic topic topic topic sum doc len feature get length adjust value topic index topic count weight populate topic count fill doc topic count 0 readjust topic stat 0 doc len token++ doc topic count doc topic ++ iterate over word document 0 doc len token++ type feature get index position old topic doc topic current type topic count type topic count type current type topic count size 0 readjust topic stat count doc topic count old topic adjust value current type topic count adjust put value old topic 1 1 adjust value 0 current type topic count old topic adjust value 1 illegal count topic go negative topic old topic build over topic topic index current type topic count key topic count current type topic count get value topic topic index length t o o yipe memory allocation inner loop note key get value too topic sum 0 0 topic count length i++ topic topic index weight topic count + beta topic topic + beta sum doc topic count topic + alpha topic topic sum + weight topic topic weight sample topic assignment topic topic index random next discrete topic topic sum readjust topic stat put topic into count doc topic topic doc topic count topic ++ type topic count type adjust put value topic 1 1 topic topic ++ save alpha estimation update document topic count histogram dirichlet estimation doc length count doc len ++ topic 0 topic num topic topic++ topic doc count topic doc topic count topic ++ sample topic doc feature feature topic save readjust topic stat currently ignore doc topic topic get feature t hash map current type topic count type old topic topic topic weight sum doc length get length populate topic count t hash map local topic count t hash map position 0 position doc length position++ local topic count adjust put value doc topic position 1 1 initialize topic count beta sampling bucket topic beta mass 0 0 topic local topic count key n local topic count get topic initialize normalization constant n t|d term topic beta mass + beta n topic topic + beta sum update coefficient zero topic cache coefficient topic alpha topic + n topic topic + beta sum topic term mass 0 0 topic term score num topic topic term index topic term value score iterate over position word document position 0 position doc length position++ type get index position position old topic doc topic position current type topic count type topic count type current type topic count get old topic 0 count note we actually want key go zero 0 current type topic count get old topic 1 current type topic count old topic current type topic count adjust value old topic 1 smooth mass alpha old topic beta topic old topic + beta sum topic beta mass beta local topic count get old topic topic old topic + beta sum local topic count get old topic 1 local topic count old topic local topic count adjust value old topic 1 topic old topic smooth mass + alpha old topic beta topic old topic + beta sum topic beta mass + beta local topic count get old topic topic old topic + beta sum cache coefficient old topic alpha old topic + local topic count get old topic topic old topic + beta sum topic term mass 0 0 topic term index current type topic count key topic term value current type topic count get value 0 topic term index length i++ topic topic term index score cache coefficient topic topic term value alpha topic + local topic count get topic topic term value topic topic + beta sum note next bit score 0 didn t difference least first few iteration topic term mass + score topic term score score topic term index topic indicate last topic topic term index 1 sample random next uniform smooth mass + topic beta mass + topic term mass orig sample sample sure actually get topic 1 sample topic term mass topic term count++ 1 sample 0 i++ sample topic term score topic topic term index sample topic term mass sample topic beta mass beta topic count++ sample beta topic term index local topic count key topic term value local topic count get value 0 topic term index length i++ topic topic term index sample topic term value topic topic + beta sum sample 0 0 smooth count++ sample topic beta mass sample beta topic 0 topic num topic topic++ sample alpha topic topic topic + beta sum sample 0 0 topic topic topic 1 err l hyp sampling + orig sample + + sample + + smooth mass + + topic beta mass + + topic term mass topic num topic 1 t o o appropriate illegal l hyp topic sample topic 1 put topic into count doc topic position topic current type topic count adjust put value topic 1 1 smooth mass alpha topic beta topic topic + beta sum topic beta mass beta local topic count get topic topic topic + beta sum local topic count adjust put value topic 1 1 topic topic ++ update coefficient zero topic cache coefficient topic alpha topic + local topic count get topic topic topic + beta sum smooth mass + alpha topic beta topic topic + beta sum topic beta mass + beta local topic count get topic topic topic + beta sum current type topic count get topic 0 clean up our mess reset coefficient value smooth next doc update zero topic topic local topic count key cache coefficient topic alpha topic topic topic + beta sum save update document topic count histogram dirichlet estimation doc length count doc length ++ topic local topic count key topic doc count topic local topic count get topic ++ sorter get sort topic word topic sorter sort type sorter num type type 0 type num type type++ sort type type sorter type type topic count type get topic sort sort type sort type print top word num word line o print stream print stream print top word num word line close tree 70x fast rank feature vector m print top word print stream num word line topic 0 topic num topic topic++ tree sorter sort word tree sorter type 0 type num type type++ type topic count type contain key topic sort word add sorter type type topic count type get topic line topic + topic word 1 iterator sorter iterator sort word iterator iterator next word num word sorter info iterator next alphabet lookup info get + + info get weight word++ print topic + + formatt format alpha topic + + topic topic + word 1 iterator sorter iterator sort word iterator iterator next word num word sorter info iterator next print alphabet lookup info get + word++ topic xml report print writer num word ?xml 1 0 ? topic model topic 0 topic num topic topic++ topic + topic + alpha + alpha topic + total + topic topic + tree sorter sort word tree sorter type 0 type num type type++ type topic count type contain key topic sort word add sorter type type topic count type get topic word 1 iterator sorter iterator sort word iterator iterator next word num word sorter info iterator next word rank + word + + alphabet lookup info get + word word++ topic topic model topic xml report phrase print stream num word num topic get num topic gnu trove t hash map phrase gnu trove t hash map num topic alphabet alphabet get alphabet get count phrase ti 0 ti num topic ti++ phrase ti gnu trove t hash map di 0 di get size di++ l hyp topication t get get di instance instance t instance feature fv feature instance get bigram fv feature bigram bigram prevtopic 1 prevfeature 1 topic 1 buffer sb feature 1 doclen fv size pi 0 pi doclen pi++ feature fv get index position pi topic get get di topic get index position pi topic prevtopic bigram || feature bigram fv get bi index position pi 1 sb sb buffer alphabet lookup prevfeature + + alphabet lookup feature sb append sb append alphabet lookup feature sb sb sb phrase +sb phrase prevtopic get sb 0 phrase prevtopic put sb 0 phrase prevtopic increment sb prevtopic prevfeature 1 sb prevtopic topic prevfeature feature phrase now fill count now start printing xml ?xml 1 0 ? topic prob alphabet size ti 0 ti num topic ti++ print topic \ + ti + \ alpha \ + alpha ti + \ total \ + topic ti + \ gathering term phrase output temporarily we can get topic information printing output stream bout output stream print stream pout print stream bout holding candidate topic title augmentable feature vector title augmentable feature vector alphabet print word type 0 type alphabet size type++ prob type get count feature topic type ti get count topic ti rank feature vector rfv rank feature vector alphabet prob ri 0 ri num word ri++ fi rfv get index rank ri pout term weight \ +prob fi + \ count \ +thi get count feature topic fi ti + \ +alphabet lookup fi + term ri 20 consider top 20 individual word candidate title title add alphabet lookup fi get count feature topic fi ti print phrase key phrase ti key value phrase ti get value count key length 0 count length i++ count value countssum matrix ops sum count alphabet alph alphabet key rfv rank feature vector alph count topic +ti max rfv num location num word ? rfv num location num word topic +ti+ num phrase +rfv num location ri 0 ri max ri++ fi rfv get index rank ri pout phrase weight \ +count fi countssum+ \ count \ +value fi + \ +alph lookup fi + phrase phrase count les 20 simply unreliable ri 20 value fi 20 title add alph lookup fi 100 value fi prefer phrase factor 100 select candidate title buffer title buffer buffer rfv rank feature vector title get alphabet title num title 10 ri 0 ri num title ri rfv num location ri++ t add redundant title title buffer index rfv get rank ri 1 title buffer append rfv get rank ri ri num title 1 title buffer append num titles++ title \ + title buffer + \ print pout topic topic print document topic f o print document topic print writer writer f print document topic print writer pw print document topic pw 0 0 1 pw print writer threshold print topic proportion great max print many topic print document topic print writer pw threshold max pw print doc topic proportion doc len topic count num topic sorter sort topic sorter num topic topic 0 topic num topic topic++ initialize sorter dummy value sort topic topic sorter topic topic max 0 || max num topic max num topic di 0 di size di++ label topic label get di topic current doc topic topic get feature pw print di pw print get di instance get pw print get di instance get pw print pw print doc len current doc topic length count up 0 doc len token++ topic count current doc topic ++ normalize topic 0 topic num topic topic++ sort topic topic topic topic count topic doc len sort sort topic 0 max i++ sort topic get weight threshold pw print sort topic get + + sort topic get weight + pw print fill topic count 0 print f o print stream print stream g z p output stream buffer output stream output stream f print close print print stream doc po typeindex type topic di 0 di size di++ feature feature get di instance get label topic label get di topic n get di instance get get di instance get pi 0 pi topic get length pi++ type get index position pi topic topic get index position pi print di print print print print pi print print type print print alphabet lookup type print print topic turbo topic corpus word count alphabet unigram alphabet feature counter unigram count feature counter unigram alphabet corpus word count alphabet alphabet unigram alphabet alphabet mylog 0 ? 1000000 0 math log likelihood ratio significance test significance test unigram count next unigram count next bigram count next total count min count next bigram count min count 1 0 next unigram count next bigram count log pi vu mylog next bigram count mylog unigram count log pi vnu mylog next unigram count next bigram count mylog next total count next bigram count log pi v old mylog next unigram count mylog next total count log 1mp v mylog 1 math log pi vnu log 1mp vu mylog 1 math log pi vu 2 next bigram count log pi vu + next unigram count next bigram count log pi vnu next unigram count log pi v old + unigram count next bigram count log 1mp vu log 1mp v significant bigram word write f output stream oo output stream output stream f oo write oo close o e err l hyp write l hyp + f + + e l hyp read f l hyp lda input stream ois input stream input stream f lda l hyp ois read lda initialize type topic count work around bug trove? ois close o e err reading + f + + e found e err reading + f + + e lda serialization serial u 1 u r r e n t e r l v e r o n 0 n u l l n t e g e r 1 write output stream o write u r r e n t e r l v e r o n instance list write write alphabet write topic alphabet write num topic write alpha write beta write beta sum write smooth mass write cache coefficient write iteration far write num iteration write burnin write save sample interval write optimize interval write show topic interval write word topic write output model interval write output model filename write save interval write filename write random write formatt write print log likelihood write doc length count write topic doc count fi 0 fi num type fi++ write type topic count fi ti 0 ti num topic ti++ write topic ti read input stream o found feature length read topication read alphabet alphabet read topic alphabet label alphabet read num topic read alpha read beta read beta sum read smooth mass read cache coefficient read iteration far read num iteration read burnin read save sample interval read optimize interval read show topic interval read word topic read output model interval read output model filename read save interval read filename read random random read formatt format read print log likelihood read doc length count read topic doc count read num doc size num type alphabet size type topic count t hash map num type fi 0 fi num type fi++ type topic count fi t hash map read topic num topic ti 0 ti num topic ti++ topic ti read topic label mutual information doc level label topic type doc topic get 0 instance get target alphabet 0 0 target alphabet size get 0 instance get target alphabet size topic label count num topic target alphabet size topic count num topic label count target alphabet size total 0 doc 0 doc size doc++ label get doc instance get label get best index label topic label get doc topic doc topic topic get feature 0 doc topic length token++ topic doc topic topic label count topic label ++ topic count topic ++ label count label ++ total++ block print best topic label sorter wp sorter num type topic 0 topic num topic topic++ type 0 type num type type++ wp type sorter type type topic count type topic topic topic sort wp buffer buffer 0 8 i++ append instance get alphabet lookup wp append label 0 label topic label count topic length label++ topic label count topic label + + instance get target alphabet lookup label topic entropy 0 0 label entropy 0 0 joint entropy 0 0 p log2 math log 2 topic 0 topic topic count length topic++ topic count topic 0 p topic count topic total topic entropy p math log p log2 label 0 label label count length label++ label count label 0 p label count label total label entropy p math log p log2 topic 0 topic topic count length topic++ label 0 label label count length label++ topic label count topic label 0 p topic label count topic label total joint entropy p math log p log2 topic entropy + label entropy joint entropy empirical likelihood num sample instance testing likelihood testing size num sample multinomial num type topic current sample current weight dirichlet topic prior dirichlet alpha sample doc topic type seq len feature f sample 0 sample num sample sample++ topic topic prior next fill multinomial 0 0 topic 0 topic num topic topic++ type 0 type num type type++ multinomial type + topic topic beta + type topic count type get topic beta sum + topic topic convert log probability type 0 type num type type++ multinomial type 0 0 multinomial type math log multinomial type doc 0 doc testing size doc++ f feature testing get doc get seq len f get length 0 seq len token++ type f get index position add check since testing instance type found training instance point steven bethard type num type likelihood doc sample + multinomial type average log likelihood 0 0 log num sample math log num sample doc 0 doc testing size doc++ max n e g t v e n f n t y sample 0 sample num sample sample++ likelihood doc sample max max likelihood doc sample sum 0 0 sample 0 sample num sample sample++ sum + math likelihood doc sample max average log likelihood + math log sum + max log num sample average log likelihood model log likelihood log likelihood 0 0 zero topic likelihood model dirichlet multinomial word topic dirichlet multinomial topic document likelihood function dirichlet multinomial gamma sum alpha prod gamma alpha + n prod gamma alpha gamma sum alpha + n log likelihood log gamma sum alpha log gamma sum alpha + n + sum log gamma alpha + n log gamma alpha document first topic count num topic topic log gamma num topic doc topic topic 0 topic num topic topic++ topic log gamma topic dirichlet log gamma stirl alpha topic doc 0 doc size doc++ label topic label get doc topic doc topic topic get feature 0 doc topic length token++ topic count doc topic ++ topic 0 topic num topic topic++ topic count topic 0 log likelihood + dirichlet log gamma stirl alpha topic + topic count topic topic log gamma topic subtract count + parameter sum term log likelihood dirichlet log gamma stirl alpha sum + doc topic length fill topic count 0 add parameter sum term log likelihood + size dirichlet log gamma stirl alpha sum topic count type topic pair zero type topic 0 type 0 type num type type++ topic type topic count type key topic topic count type topic count type get topic count 0 zero type topics++ log likelihood + dirichlet log gamma stirl beta + count topic 0 topic num topic topic++ log likelihood dirichlet log gamma stirl beta num topic + topic topic log likelihood + dirichlet log gamma stirl beta num topic dirichlet log gamma stirl beta zero type topic log likelihood recommend bin vectors2topic instead o instance training instance load 0 num topic length 1 ? parse 1 200 instance testing length 2 ? instance load 2 l hyp lda l hyp num topic 50 0 0 01 lda print log likelihood lda topic 50 7 lda add instance training lda estimate 