2009 univ dept part m l l e t m achine learning languag e toolkit 1 0 information see ` l e n e semi supervise transducer type feature vector math run subsequence constrain forward backward compute entropy label sequence p reference gideon mann mc callum efficient computation entropy gradient semi supervise conditional random field h l t n l 2007 gideon mann gaurav chandalia gregory druck entropy lattice input size + 1 lattice length input size input length model transducer transducer lattice model finite machine num ip input position node forward backward factor forward backward algorithm index ip ip index si lattice node node subsequence constrain forward entropy entropy run constrain forward backward p tt incrementor tt update expectation due these computation p entropy expectation multiplie scaling factor entropy lattice feature vector fv gamma xi transducer transducer transducer incrementor incrementor scaling factor input length fv size lattice length input length + 1 transducer transducer num transducer num node lattice node lattice length num run forward backward compute entropy entropy forward lattice gamma xi backward entropy backward lattice gamma xi math almost equal entropy backward entropy entropy + + backward entropy incrementor add entropy expectation update count fv gamma xi scaling factor incrementor get entropy entropy compute forward entropy h^alpha forward lattice gamma xi initialize entropy start 0 0 num ++a get lattice node 0 alpha 0 ip 1 ip lattice length ++ip 0 num ++a position ip 1 input lattice node node get lattice node ip gamma gamma ip gamma transducer m p o l e w e g h t 0 num ++b position ip input coming xi xi ip 1 xi transducer m p o l e w e g h t p y ip 1 b|y ip cond prob math xi math gamma node alpha + cond prob xi gamma + get lattice node ip 1 alpha entropy 0 0 0 num ++a gamma gamma input length gamma prob math gamma gamma transducer m p o l e w e g h t entropy + gamma prob gamma entropy + gamma prob get lattice node input length alpha entropy compute backward entropy h^beta backward lattice gamma xi initialize entropy 0 0 num ++a get lattice node input length beta 0 ip input length ip 0 ip 0 num ++a position ip 1 input lattice node node get lattice node ip gamma gamma ip gamma transducer m p o l e w e g h t 0 num ++b position ip input xi xi ip xi transducer m p o l e w e g h t p y ip b|y ip 1 cond prob math xi math gamma node beta + cond prob xi gamma + get lattice node ip+1 beta entropy 0 0 0 num ++a gamma gamma 0 gamma prob math gamma gamma transducer m p o l e w e g h t entropy + gamma prob gamma entropy + gamma prob get lattice node 0 beta entropy update expectation due entropy p update count feature vector fv gamma xi scaling factor transducer incrementor incrementor ip 0 ip input length ++ip 0 num ++a node ip transducer transducer get transducer transition iterator it transition iterator fv ip ip it next it next get index xi xi ip xi transducer m p o l e w e g h t xi prob math xi obtain substituting re arranging equation page paper into equation theta h y|x second page \sum y y i+1 f k y y i+1 p y y i+1 log p y y i+1 + h^a y 1 1 y + h^b y i+2 t |y i+1 constr entropy xi prob xi + node ip alpha + node ip+1 beta constr entropy 0 negative entropy negative + constr entropy full covariance note could positive negative cov constr entropy xi prob entropy na n cov xi + xi + node + ip + + + alpha + node ip alpha + node + ip+1 + + + beta + node ip+1 beta incrementor increment transition it cov scaling factor lattice node get lattice node ip si node ip si node ip si lattice node ip transducer get si node ip si contain alpha beta value input position pair lattice node ip transducer alpha beta lattice node ip transducer ip ip alpha 0 0 beta 0 0 