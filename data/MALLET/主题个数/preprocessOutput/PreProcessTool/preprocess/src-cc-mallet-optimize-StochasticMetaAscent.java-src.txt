optimize logging logger decimal format optimize optimiz type matrix ops logger greg druck kedar bellare stochastic meta ascent optimiz batch logger logger logger get logger stochastic meta ascent get name m t e r 200 l m 1 0 t o l e r n e 0 01 e p 1e 10 mu 0 1 total iteration 0 eta init 0 03 hessian gain gradient trace optimizable batch gradient maxable stochastic meta ascent optimizable batch gradient maxable maxable maxable step step eta init step mu m mu m hessian flag hessian flag optimize num batch batch assignment optimize m t e r num batch batch assignment optimize num iteration num batch batch assignment num maxable get num num gradient num hessian num initialize these they someone want optimize few iteration gain err stochastic meta ascent step +eta init+ meta step +mu gain num fill gain eta init gradient trace num maxable get iteration 0 iteration num iteration iteration++ old approx value 0 approx value 0 batch 0 batch num batch batch++ logger info iteration + total iteration + iteration + batch + batch + + num batch get current maxable get update value gradient current batch value maxable get batch value batch batch assignment old approx value + value na n value illegal argument na n value computation probably you need reduce step meta step maxable get batch value gradient gradient batch batch assignment below originally write stochastic meta descent we maximize we want ascent flip sign gradient point downhill matrix ops time equal gradient 1 hessian compute hessian maxable batch batch assignment gradient gradient trace hessian report vec report vec step gain report vec grad gradient report vec trace gradient trace update learning rate individual index 0 index num index++ first iteration just step since gradient trace zero gain index math max 0 5 1 mu gradient index gradient trace index adjust direction index gain index gradient index hessian adjust gradient trace gradient trace index l m gradient trace index gain index gradient index + l m hessian index adjust gradient trace gradient trace index l m gradient trace index gain index gradient index + l m gradient trace index maxable value maxable get batch value batch batch assignment approx value + value logger info stochastic meta ascent value +initial value+ value +final value logger info stochastic meta descent value iteration + total iteration + iteration + + approx value converge criterion gradient ascent memory f g 2 0 math ab approx value old approx value t o l e r n e math ab approx value + math ab old approx value + e p logger info stochastic meta ascent value difference + math ab approx value old approx value + below + tolerance saying converge total iteration + iteration old approx value approx value total iteration + num iteration report vec v decimal format f decimal format 0 stochastic meta ascent +s+ + min + f format matrix ops min v + max + f format matrix ops max v + + f format matrix ops v + 2norm + f format matrix ops two norm v + ab norm + f format matrix ops ab norm v compute finite difference approximation hessian compute hessian optimizable batch gradient maxable batch index batch assignment current gradient vector num maxable get num ep 1 0e 6 ep gradient num old num adjust ep vector recompute gradient arraycopy 0 old 0 num matrix ops plus equal vector ep maxable maxable get batch value gradient ep gradient batch index batch assignment restore old maxable old calculate hessian index 0 index length index++ index ep gradient index current gradient index ep 