2005 univ dept part m l l e t m achine learning languag e toolkit 1 0 information see ` l e n e topic io type util random latent dirichlet allocation mc callum deprecate parallel topic model instead think about support incrementally add document think we want feature directly we also need support growing vocabulary l serializable num topic topic fit alpha dirichlet alpha alpha over topic beta prior topic multinomial over word t alpha v beta instance ilist instance expect hold feature topic index document index index num type num doc topic count index document index topic index type topic count index feature index topic index topic index topic index l topic topic 50 0 0 01 l topic alpha sum beta num topic topic alpha alpha sum num topic beta beta estimate instance document num iteration show topic interval output model interval output model filename random r ilist document shallow clone num type ilist get alphabet size num doc ilist size topic num doc doc topic count num doc num topic type topic count num type num topic topic num topic t alpha alpha num topic v beta beta num type start current milli initialize random assignment topic finish allocate topic topic seq len feature f di 0 di num doc di++ f feature ilist get di get cast e err l topic model expect feature feature vector + text2vector you can keep keep bisequence e seq len f get length num + seq len topic di seq len randomly topic si 0 si seq len si++ topic r next num topic topic di si topic doc topic count di topic ++ type topic count f get index position si topic ++ topic topic ++ estimate 0 num doc num iteration show topic interval output model interval output model filename r 124 5 second 144 8 second feature instead 121 6 second putting feature get index position 106 3 second avoid lookup inner loop temporary variable add document instance additional document num iteration show topic interval output model interval output model filename random r ilist illegal already some document first instance inst additional document ilist add inst ilist get alphabet additional document get alphabet additional document get alphabet size num type num type additional document get alphabet size num doc additional document size num old doc topic length num doc num old docs+ num doc expand variou space topic num doc 0 topic length i++ topic topic topic topic rest initialize below doc topic count num doc num topic 0 doc topic count length i++ doc topic count doc topic count doc topic count doc topic count rest initialize below type topic count num type num topic 0 type topic count length i++ j 0 j num topic j++ type topic count j type topic count j populate below feature f di num old doc di num doc di++ f feature additional document get di num old doc get cast e err l topic model expect feature feature vector + text2vector you can keep keep bisequence e seq len f get length num + seq len topic di seq len randomly topic si 0 si seq len si++ topic r next num topic topic di si topic doc topic count di topic ++ type topic count f get index position si topic ++ topic topic ++ several round gibbs sampling document range estimate doc index start doc index length num iteration show topic interval output model interval output model filename random r start current milli iteration 0 iteration num iteration iterations++ iteration % 10 0 print iteration print flush show topic interval 0 iteration % show topic interval 0 iteration 0 print top word 5 output model interval 0 iteration % output model interval 0 iteration 0 write output model filename+ +iteration sample topic doc doc index start doc index length r second math round current milli start 1000 0 minute second 60 second % 60 hour minute 60 minute % 60 day hour 24 hour % 24 print total day 0 print day print day hour 0 print hour print hour minute 0 print minute print minute print second second iteration gibbs sampling acros document sample topic doc random r topic weight num topic loop over word corpus di 0 di topic length di++ sample topic doc feature ilist get di get topic di doc topic count di topic weight r iteration gibbs sampling acros document sample topic doc start length random r start+length doc topic count length topic weight num topic loop over word corpus di start di start+length di++ sample topic doc feature ilist get di get topic di doc topic count di topic weight r topic test random r test topic test length test topic count num topic num matrix ops sum test topic weight num topic randomly topic word incorporate document global count topic si 0 si test length si++ topic r next num topic test topic si topic analogou topic test topic count topic ++ analogou doc topic count type topic count test si topic ++ topic topic ++ repeatedly sample topic assignment word document iteration 0 iteration num 2 iterations++ sample topic doc test test topic test topic count topic weight r document global count also fill topic weight unnormaliz over topic whole doc fill topic weight 0 0 si 0 si test length si++ topic test topic si type topic count test si topic topic topic topic weight topic ++ normalize over topic whole doc ti 0 ti num topic ti++ topic weight ti test length topic weight sample topic doc feature doc doc topic index seq position doc topic count index topic index topic weight random r current type topic count type old topic topic topic weight sum doc len doc get length tw iterate over position word document si 0 si doc len si++ type doc get index position si old topic doc topic si count doc topic count old topic type topic count type old topic topic old topic build over topic fill topic weight 0 0 topic weight sum 0 current type topic count type topic count type ti 0 ti num topic ti++ tw current type topic count ti + beta topic ti + v beta doc topic count ti + alpha doc len 1+t alpha constant acros topic topic weight sum + tw topic weight ti tw sample topic assignment topic r next discrete topic weight topic weight sum put topic into count doc topic si topic doc topic count topic ++ type topic count type topic ++ topic topic ++ get doc topic count doc topic count get type topic count type topic count get topic topic print top word num word line word prob comparable wi p word prob wi p wi wi p p compare o2 p word prob o2 p 1 p word prob o2 p 0 1 word prob wp word prob num type ti 0 ti num topic ti++ wi 0 wi num type wi++ wp wi word prob wi type topic count wi ti topic ti sort wp line topic +ti 0 num word i++ ilist get alphabet lookup wp wi + + wp p print topic +ti+ 0 num word i++ print ilist get alphabet lookup wp wi + print document topic f o print document topic print writer writer f print document topic print writer pw print document topic pw 0 0 1 print document topic print writer pw threshold max pw doc topic proportion doc len topic dist topic length di 0 di topic length di++ pw print di pw print ilist get di get pw print ilist get di get pw print pw print doc len topic di length ti 0 ti num topic ti++ topic dist ti doc topic count di ti doc len max 0 max num topic tp 0 tp max tp++ maxvalue 0 maxindex 1 ti 0 ti num topic ti++ topic dist ti maxvalue maxvalue topic dist ti maxindex ti maxindex 1 || topic dist maxindex threshold pw print maxindex+ +topic dist maxindex + topic dist maxindex 0 pw print f o print writer writer print writer writer f print writer writer close print print writer pw alphabet ilist get alphabet pw doc po typeindex type topic di 0 di topic length di++ feature f feature ilist get di get si 0 si topic di length si++ type f get index position si pw print di pw print pw print si pw print pw print type pw print pw print lookup type pw print pw print topic di si pw write f output stream oo output stream output stream f oo write oo close o e err + f + + e serialization serial u 1 u r r e n t e r l v e r o n 0 n u l l n t e g e r 1 write output stream o write u r r e n t e r l v e r o n write ilist write num topic write alpha write beta write t alpha write v beta di 0 di topic length di ++ si 0 si topic di length si++ write topic di si di 0 di topic length di ++ ti 0 ti num topic ti++ write doc topic count di ti fi 0 fi num type fi++ ti 0 ti num topic ti++ write type topic count fi ti ti 0 ti num topic ti++ write topic ti read input stream o found feature length read ilist instance read num topic read alpha read beta read t alpha read v beta read num doc ilist size topic num doc di 0 di ilist size di++ doc len feature ilist get di get get length topic di doc len si 0 si doc len si++ topic di si read doc topic count num doc num topic di 0 di ilist size di++ ti 0 ti num topic ti++ doc topic count di ti read num type ilist get alphabet size type topic count num type num topic fi 0 fi num type fi++ ti 0 ti num topic ti++ type topic count fi ti read topic num topic ti 0 ti num topic ti++ topic ti read instance get instance ilist recommend bin vectors2topic instead o instance ilist instance load 0 num iteration length 1 ? parse 1 1000 num top word length 2 ? parse 2 20 load l lda l 10 lda estimate ilist num iteration 50 0 random 1100 lda print top word num top word lda print document topic 0 + lda 