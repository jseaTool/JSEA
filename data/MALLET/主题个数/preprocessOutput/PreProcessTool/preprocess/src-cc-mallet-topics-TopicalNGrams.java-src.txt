2005 univ dept part m l l e t m achine learning languag e toolkit 1 0 information see ` l e n e topic io type random latent dirichlet allocation integrate phrase discovery mc callum xuerui wang topical n gram num topic alphabet uni alphabet alphabet bi alphabet alpha beta gamma delta t alpha v beta v gamma delta1 delta2 instance ilist contain feature bigram instance topic 0 t 1 topic index index document index index gram 0 1 bigram status index document index index t o o boolean? num type unique unigram num bitype unique bigram num total word occurrence total ngram bi total currently generate bigram progress message doc topic doc topic count index document index topic index calculate p x|w t ngram count type ngram topic count index feature index ngram status topic index calculate p w|t p w|t w topic word topic ngram word unitype topic count index feature index topic index bitype topic count index bifeature index topic index sum word topic index topic index sum ngram word bitoken topic index feature index topic index late condition word topical n gram topic topic 50 0 0 01 0 01 0 03 0 2 1000 topical n gram topic alpha sum beta gamma delta delta1 delta2 num topic topic alpha alpha sum num topic smooth over choice topic beta beta smooth over choice unigram word gamma gamma smooth over choice bigram word delta delta smooth over choice unigram bigram generation delta1 delta1 t o o clean up delta2 delta2 alpha +alpha sum beta +beta gamma +gamma delta +delta delta1 +delta1 delta2 +delta2 estimate instance document num iteration show topic interval output model interval output model filename random r ilist document uni alphabet ilist get alphabet bi alphabet feature bigram ilist get 0 get get bi alphabet num type uni alphabet size num bitype bi alphabet size num doc ilist size topic num doc gram num doc doc topic count num doc num topic type ngram topic count num type 2 num topic unitype topic count num type num topic bitype topic count num bitype num topic topic num topic bitoken topic num type num topic t alpha alpha num topic v beta beta num type v gamma gamma num type start current milli initialize random assignment topic finish allocate topic topic gram seq len fi di 0 di num doc di++ feature bigram f feature bigram ilist get di get seq len f get length num + seq len topic di seq len gram di seq len randomly topic prev fi 1 prev topic 1 si 0 si seq len si++ randomly sample topic word position si topic r next num topic bigram allow position si sample gram status gram f get bi index position si 1 ? 0 r next 2 gram 0 bi tokens++ topic di si topic gram di si gram doc topic count di topic ++ fi f get index position si prev fi 1 type ngram topic count prev fi gram prev topic ++ gram 0 unitype topic count fi topic ++ topic topic ++ bitype topic count f get bi index position si topic ++ bitoken topic prev fi topic ++ prev fi fi prev topic topic iteration 0 iteration num iteration iterations++ sample topic doc r iteration % 10 0 print iteration print flush show topic interval 0 iteration % show topic interval 0 iteration 0 print top word 5 output model interval 0 iteration % output model interval 0 iteration 0 write output model filename+ +iteration total sec + current milli start 1000 0 iteration gibbs sampling acros document sample topic doc random r uni topic weight num topic bi topic weight num topic 2 loop over word corpus di 0 di topic length di++ sample topic doc feature bigram ilist get di get topic di gram di doc topic count di uni topic weight bi topic weight r sample topic doc feature bigram doc doc topic doc gram doc topic count index topic index uni topic weight length num topic bi topic weight length num topic 2 joint topic gram sampling random r current type topic count current bitype topic count previou bitoken topic type bitype old gram next gram gram old topic topic topic weight sum tw xxx doc len doc length doc len doc get length iterate over position word document si 0 si doc len si++ type doc get index position si bitype doc get bi index position si bitype 1 biblock +si+ +uni alphabet lookup type old topic doc topic si old gram doc gram si next gram si doc len 1 ? 1 doc gram si+1 next gram si doc len 1 ? 1 doc get bi index position si+1 1 ? 0 1 bigram possible bitype 1 bigram possible old gram 1 bigram possible count doc topic count old topic topic old topic unitype topic count type old topic si doc len 1 type ngram topic count type next gram old topic type ngram topic count type next gram old topic 0 doc topic count old topic 0 topic old topic 0 unitype topic count type old topic 0 build over topic fill uni topic weight 0 0 topic weight sum 0 current type topic count unitype topic count type ti 0 ti num topic ti++ tw current type topic count ti + beta topic ti + v beta doc topic count ti + alpha additional term constance acros topic topic weight sum + tw uni topic weight ti tw sample topic assignment topic r next discrete uni topic weight topic weight sum put topic into count doc topic si topic doc topic count topic ++ unitype topic count type topic ++ topic topic ++ si doc len 1 type ngram topic count type next gram topic ++ bigram possible prev type doc get index position si 1 prev topic doc topic si 1 count doc topic count old topic type ngram topic count prev type old gram prev topic si doc len 1 type ngram topic count type next gram old topic old gram 0 unitype topic count type old topic topic old topic bitype topic count bitype old topic bitoken topic prev type old topic bi doc topic count old topic 0 type ngram topic count prev type old gram prev topic 0 si doc len 1 || type ngram topic count type next gram old topic 0 unitype topic count type old topic 0 topic old topic 0 bitype topic count bitype old topic 0 bitoken topic prev type old topic 0 bi 0 build joint over topic ngram status fill bi topic weight 0 0 topic weight sum 0 current type topic count unitype topic count type current bitype topic count bitype topic count bitype previou bitoken topic bitoken topic prev type ti 0 ti num topic ti++ topic ti 1 just variable index into ti 2+gram unigram outcome tw current type topic count ti + beta topic ti + v beta doc topic count ti + alpha type ngram topic count prev type 0 prev topic + delta1 topic weight sum + tw bi topic weight topic tw bigram outcome topic++ tw current bitype topic count ti + gamma previou bitoken topic ti + v gamma doc topic count ti + alpha type ngram topic count prev type 1 prev topic + delta2 topic weight sum + tw bi topic weight topic tw sample topic assignment topic r next discrete bi topic weight topic weight sum put topic into count gram topic % 2 topic 2 put topic into count doc topic si topic doc gram si gram doc topic count topic ++ type ngram topic count prev type gram prev topic ++ si doc len 1 type ngram topic count type next gram topic ++ gram 0 unitype topic count type topic ++ topic topic ++ bitype topic count bitype topic ++ bitoken topic prev type topic ++ bi tokens++ print top word num word line word prob comparable wi p word prob wi p wi wi p p compare o2 p word prob o2 p 1 p word prob o2 p 0 1 ti 0 ti num topic ti++ unigram word prob wp word prob num type wi 0 wi num type wi++ wp wi word prob wi unitype topic count wi ti sort wp num print math min wp length num word line topic +ti+ unigram 0 num print i++ uni alphabet lookup wp wi + + wp p topic ti print topic +ti+ 0 num print i++ print uni alphabet lookup wp wi + bigram wp word prob num bitype bisum 0 wi 0 wi num bitype wi++ wp wi word prob wi bitype topic count wi ti bisum + bitype topic count wi ti sort wp num print math min wp length num word line topic +ti+ bigram 0 num print i++ bi alphabet lookup wp wi + + wp p bisum print 0 num print i++ print bi alphabet lookup wp wi + ngram augmentable feature vector afv augmentable feature vector alphabet 10000 di 0 di topic length di++ feature bigram f feature bigram ilist get di get si topic di length 1 si 0 si topic di si ti gram di si 1 gram uni alphabet lookup f get index position si gram di si 1 si 0 gram uni alphabet lookup f get index position si + + gram afv add gram 1 0 pre sorting num ngram afv num location post sorting +num ngram wp word prob num ngram ngram sum 0 loc 0 loc num ngram loc++ wp loc word prob afv index location loc afv value location loc ngram sum + wp loc p sort wp num unitype 0 num bitype 0 num unitype type 0 num bitype type 0 fi 0 fi num type fi++ num unitype + unitype topic count fi ti unitype topic count fi ti 0 num unitype types++ fi 0 fi num bitype fi++ num bitype + bitype topic count fi ti bitype topic count fi ti 0 num bitype types++ line topic +ti+ unigram +num unitype tokens+ +num unitype types+ bigram +num bitype tokens+ +num bitype type + phrase + math round afv norm + +num ngram 0 math min num ngram num word i++ afv get alphabet lookup wp wi + + wp p ngram sum print unigram +num unitype tokens+ +num unitype types+ bigram +num bitype tokens+ +num bitype type + phrase + math round afv norm + +num ngrams+ print unique ngram +num ngrams+ ngram count + math round afv norm + 0 math min num ngram num word i++ print afv get alphabet lookup wp wi + print document topic f o print document topic print writer writer f print document topic print writer pw print document topic print writer pw threshold max pw doc topic proportion doc len topic dist topic length di 0 di topic length di++ pw print di pw print pw print ilist get di get pw print doc len topic di length ti 0 ti num topic ti++ topic dist ti doc topic count di ti doc len max 0 max num topic tp 0 tp max tp++ maxvalue 0 maxindex 1 ti 0 ti num topic ti++ topic dist ti maxvalue maxvalue topic dist ti maxindex ti maxindex 1 || topic dist maxindex threshold pw print maxindex+ +topic dist maxindex + topic dist maxindex 0 pw print f o print writer writer print writer writer f print writer writer close print print writer pw pw doc po typeindex type bigrampossible? topic bigram di 0 di topic length di++ feature bigram f feature bigram ilist get di get si 0 si topic di length si++ type f get index position si pw print di pw print pw print si pw print pw print type pw print pw print uni alphabet lookup type pw print pw print f get bi index position si 1 ? 0 1 pw print pw print topic di si pw print pw print gram di si pw write f output stream oo output stream output stream f oo write oo close o e err + f + + e serialization serial u 1 u r r e n t e r l v e r o n 0 n u l l n t e g e r 1 write array2 output stream o write length d2 0 length write d2 0 length i++ j 0 j d2 j++ write j read array2 input stream o d1 read d2 read d1 d2 0 d1 i++ j 0 j d2 j++ j read write output stream o write u r r e n t e r l v e r o n write ilist write num topic write alpha write beta write gamma write delta write t alpha write v beta write v gamma write num type write num bitype write num write bi di 0 di topic length di ++ si 0 si topic di length si++ write topic di si di 0 di topic length di ++ si 0 si topic di length si++ write gram di si write array2 doc topic count fi 0 fi num type fi++ n 0 n 2 n++ ti 0 ti num topic ti++ write type ngram topic count fi n ti write array2 unitype topic count write array2 bitype topic count ti 0 ti num topic ti++ write topic ti write array2 bitoken topic read input stream o found feature length read ilist instance read num topic read alpha read beta read gamma read delta read t alpha read v beta read v gamma read num type read num bitype read num read bi read num doc ilist size topic num doc gram num doc di 0 di ilist size di++ doc len feature ilist get di get get length topic di doc len si 0 si doc len si++ topic di si read di 0 di ilist size di++ doc len feature ilist get di get get length gram di doc len si 0 si doc len si++ gram di si read doc topic count read array2 type ngram topic count num type 2 num topic fi 0 fi num type fi++ n 0 n 2 n++ ti 0 ti num topic ti++ type ngram topic count fi n ti read unitype topic count read array2 bitype topic count read array2 topic num topic ti 0 ti num topic ti++ topic ti read bitoken topic read array2 just testing recommend instead bin vectors2topic instance ilist instance load 0 num iteration length 1 ? parse 1 1000 num top word length 2 ? parse 2 20 load topical n gram tng topical n gram 10 tng estimate ilist 200 1 0 random tng print top word 60 