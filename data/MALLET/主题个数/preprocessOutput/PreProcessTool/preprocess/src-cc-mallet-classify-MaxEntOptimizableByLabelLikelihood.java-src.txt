classify io serializable iterator logging logger optimize memory f g optimize optimizable type alphabet type feature selection type feature vector type instance type instance type label alphabet type label type matrix ops logger progress message logger math max ent optimizable label likelihood optimizable gradient value logger logger logger get logger max ent optimizable label likelihood get name logger progress logger progress message logger get logger max ent optimizable label likelihood get name + pl xxx why test maximizable fail variance very small? e f u l t g u n p r o r v r n e 1 e f u l t h y p e r o l p r o r l o p e 0 2 e f u l t h y p e r o l p r o r h r p n e 10 0 e f u l t m m z e r l memory f g hyperbolic prior gaussian prior gaussian prior variance e f u l t g u n p r o r v r n e hyperbolic prior slope e f u l t h y p e r o l p r o r l o p e hyperbolic prior sharpness e f u l t h y p e r o l p r o r h r p n e maximiz e f u l t m m z e r l constraint cache gradient max ent classifier instance training expectation temporarily store cache gradient cache value cache value stale cache gradient stale num label num feature feature index just clarity feature selection feature selection feature selection label feature selection num get value call 0 num get value gradient call 0 max ent optimizable label likelihood max ent optimizable label likelihood instance training max ent classifier training training alphabet fd training get alphabet label alphabet ld label alphabet training get target alphabet t fd stop growth because someone want feature induction ld stop growth add feature feature num label ld size num feature fd size + 1 feature index num feature 1 num label num feature constraint num label num feature cache gradient num label num feature fill 0 0 fill constraint 0 0 fill cache gradient 0 0 feature selection training get feature selection label feature selection training get label feature selection add feature index selection feature selection feature selection add feature index label feature selection 0 label feature selection length i++ label feature selection add feature index xxx late change both select flag? feature selection || label feature selection classifier classifier classifier classifier feature selection classifier feature selection label feature selection classifier feature selection feature index classifier feature index classifier get instance pipe training get pipe classifier classifier max ent training get pipe feature selection label feature selection cache value stale cache gradient stale initialize constraint logger fine instance training + training size instance inst training instance weight training get instance weight inst label label inst get label label logger fine instance +ii+ label +label feature vector fv feature vector inst get alphabet fdict fv get alphabet fv get alphabet fd label get best index matrix ops row plus equal constraint num feature fv instance weight feature weight 1 0 na n instance weight instance weight na n na n best index na n na n 0 fv num location i++ na n fv value location logger info na n feature + fdict lookup fv index location na n na n logger info na n instance + inst get name constraint num feature + feature index + 1 0 instance weight test maximizable test value gradient current max ent get classifier classifier get parameter index index parameter index v cache value stale cache gradient stale index v get num length get buff buff || buff length length buff length arraycopy 0 buff 0 length buff buff cache value stale cache gradient stale buff length length buff length arraycopy buff 0 0 buff length log probability training label get value cache value stale num get value calls++ cache value 0 we ll store expectation value cache gradient now cache gradient stale matrix ops cache gradient 0 0 incorporate likelihood score training get target alphabet size value 0 0 iterator instance it training iterator 0 it next ii++ instance instance it next instance weight training get instance weight instance label label instance get label label l now +input alphabet size + regular feature classifier get classification score instance score feature vector fv feature vector instance get label get best index value instance weight math log score na n value logger fine max ent trainer instance + instance get name + na n value log score + math log score + score + score + instance weight + instance weight infinite value logger warning instance +instance get + infinite value skip value gradient cache value value cache value stale value cache value + value si 0 si score length si++ score si 0 infinite score si matrix ops row plus equal cache gradient num feature si fv instance weight score si cache gradient num feature si + feature index + instance weight score si logger info expectation cache gradient print incorporate prior prior 0 hyperbolic prior 0 num label li++ fi 0 fi num feature fi++ prior + hyperbolic prior slope hyperbolic prior sharpness math log math cosh hyperbolic prior sharpness num feature + fi gaussian prior 0 num label li++ fi 0 fi num feature fi++ num feature + fi prior + 2 gaussian prior variance o value cache value cache value + prior cache value 1 0 m m z e n o t m n m z e cache value stale progress logger info value label prob +o value+ prior +prior+ loglikelihood +cach value cache value get value gradient buffer gradient constraint expectation gaussian prior variance cache gradient stale num get value gradient calls++ cache value stale fill cache gradient expectation get value matrix ops plus equal cache gradient constraint incorporate prior hyperbolic prior unsupport operation hyperbolic prior yet gaussian prior matrix ops plus equal cache gradient 1 0 gaussian prior variance parameter infinity external user we gradient 0 because parameter value can nev change anyway mess up future calculation matrix norm matrix ops substitute cache gradient n e g t v e n f n t y 0 0 zero gradient dimension among select feature label feature selection label index 0 label index num label label index++ matrix ops row cache gradient num feature label index 0 0 feature selection label index 0 label index num label label index++ matrix ops row cache gradient num feature label index 0 0 label feature selection label index cache gradient stale buffer buffer length length arraycopy cache gradient 0 buffer 0 cache gradient length max ent trainer gradient infinity norm + matrix ops infinity norm cache gradient these really public? why? count many time trainer compute gradient log probability training label get value gradient call num get value gradient call count many time trainer compute log probability training label get value call num get value call get iteration maximiz gradient get iteration max ent optimizable label likelihood gaussian prior gaussian prior hyperbolic prior max ent optimizable label likelihood hyperbolic prior gaussian prior hyperbolic prior some prior term optimiz eg orthant wise l f g we occasionally want calculate log likelihood max ent optimizable label likelihood prior gaussian prior hyperbolic prior set parameter prevent overtrain small variance prior feature weight expect hover closer 0 extra evidence high weight trainer max ent optimizable label likelihood gaussian prior variance gaussian prior variance gaussian prior hyperbolic prior gaussian prior variance gaussian prior variance max ent optimizable label likelihood hyperbolic prior slope hyperbolic prior slope gaussian prior hyperbolic prior hyperbolic prior slope hyperbolic prior slope max ent optimizable label likelihood hyperbolic prior sharpness hyperbolic prior sharpness gaussian prior hyperbolic prior hyperbolic prior sharpness hyperbolic prior sharpness 