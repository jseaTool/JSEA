2002 univ dept part m l l e t m achine learning languag e toolkit 1 0 information see ` l e n e gain obtain add feature conditional exponential model joint exponential model della pietra della pietra lafferty 1997 we smooth gaussian prior note we math log log base 2 unit bit mc callum type logging io classify classification logger gain rank feature vector logger logger logger get logger gain get name gain feature f define max ent type feature+clas feature f f f gain feature f g f k l p ||q k l p ||q f p empirical accord label q imperfect classifier q f imperfect classifier f f weight adjust none weight adjust gain feature f g f sum g f accurate gain feature here we simply gain feature \sum gain feature xxx ev them hyperbolic prior hyperbolic slope 0 2 hyperbolic sharpness 10 0 calc gain instance ilist label vector classification gaussian prior variance num instance ilist size num ilist get target alphabet size num feature ilist get alphabet size ilist size 0 notation della pietra lafferty 1997 p 4 p p num num feature q q num num feature alpha weight feature alpha num num feature fli feature location index flv feature location value logger info starting klgain instance +num instance label weight sum 0 model label weight sum 0 calculate p f q f 0 num instance i++ classification get label alphabet ilist get target alphabet instance inst ilist get label label inst get label feature vector fv feature vector inst get instance weight ilist get instance weight below relie label weight sum 1 over label instance model label weight 0 0 num li++ label weight label value model label weight classification value label weight sum + label weight model label weight sum + model label weight instance model label weight + model label weight 500 +i+ +li+ +true label weight+ model +model label weight label weight 0 model label weight 0 fl 0 fl fv num location fl++ fli fv index location fl fv value location fl 1 0 xxx note we attent instance weight here p fli + label weight instance weight num instances+1 q fli + model label weight instance weight num instances+1 p fli + label weight q fli + model label weight math ab instance model label weight 1 0 0 001 math ab label weight sum num instance 1 0 0 001 label weight sum 1 0 +true label weight sum math ab model label weight sum num instance 1 0 0 001 model label weight sum 1 0 +model label weight sum psum 0 qsum 0 0 num i++ j 0 j num feature j++ psum + p j qsum + q j math ab psum 1 0 0 0001 psum 1 0 psum +psum+ qsum +qsum math ab qsum 1 0 0 0001 qsum 1 0 psum +psum+ qsum +qsum determine alpha we can t close della pietra paper because we here conditional max ent model we newton raphson initialize inappropriate joint close solution 0 num i++ j 0 j num feature j++ alpha j math log p j 1 0 q j q j 1 0 p j dalpha num num feature first alpha change old num num feature change alpha last iteration alpha max num num feature change alpha last iteration alpha min num num feature change alpha last iteration ddalpha num num feature second 0 num i++ j 0 j num feature j++ alpha max j p o t v e n f n t y alpha min j n e g t v e n f n t y max alphachange 0 max dalpha 99 max newton step 50 xxx change more? alpha initialize zero newton 0 max dalpha 1 0 e 8 newton max newton step newton++ newton iteration +newton hyperbolic prior 0 num i++ j 0 j num feature j++ dalpha j p j alpha j gaussian prior variance ddalpha j 1 gaussian prior variance gaussian prior 0 num i++ j 0 j num feature j++ dalpha j p j alpha j gaussian prior variance ddalpha j 1 gaussian prior variance 0 ilist size i++ classification get label alphabet ilist get target alphabet instance inst ilist get label label inst get label feature vector fv feature vector inst get xxx binary value feature what about tie weights? fl 0 fl fv num location fl++ fli fv index location fl 0 num li++ model label weight classification value expalpha math alpha fli numerator model label weight expalpha denominator numerator + 1 0 model label weight dalpha fli numerator denominator ddalpha fli + numerator numerator denominator denominator numerator denominator we now now first second newton step run test alpha derivative newton step alphachange newalpha oldalpha max alphachange max dalpha 0 0 num i++ j 0 j num feature j++ alphachange dalpha j ddalpha j p j 0 q j 0 num features+j % num num feature 2000 0 || na n alpha j || na n alphachange print just sampling them logger info alpha +i+ +j+ +alpha j + p +p j + q +q j + dalpha +dalpha j + ddalpha +ddalpha j + alphachange +alphachange+ min +alpha min j + max +alpha max j na n alpha j || na n dalpha j || na n ddalpha j || infinite alpha j || infinite dalpha j || infinite ddalpha j alphachange 0 na n alpha j na n dalpha j na n ddalpha j oldalpha alpha j xxx ddalpha j 0 math ab alphachange 100 0 alphachange xxx arbitrary? prevent cycle math ab alphachange + alpha change old j math ab alphachange 0 01 newalpha alpha j + alphachange 2 newalpha alpha j + alphachange alphachange 0 alpha max j alpha j updating alpha max +i+ +j+ +alpha j alpha max j alpha j alphachange 0 alpha min j alpha j updating alpha min +i+ +j+ +alpha j alpha min j alpha j newalpha alpha max j newalpha alpha min j newton want jump point inside boundary let alpha j newalpha newton want jump point outside boundary bisect instead alpha max j p o t v e n f n t y alpha min j n e g t v e n f n t y alpha j alpha min j + alpha max j alpha min j 2 newton exceed bound bisect dalpha +i+ +j+ +dalpha j + alpha min +alpha min j + alpha max +alpha max j alphachange alpha j oldalpha math ab alphachange max alphachange max alphachange math ab alphachange math ab dalpha j max dalpha max dalpha math ab dalpha j alpha change old j alphachange logger info +newton+ newton iteration maximum alphachange +max alphachange+ dalpha +max dalpha some memory free q ddalpha dalpha alpha change old alpha min alpha max q e^ \alpha g p 4 calculate qeag note we gaussian prior we t multiply 1 num instance qeag num num feature 0 ilist size i++ classification get label alphabet ilist get target alphabet instance inst ilist get label label inst get label feature vector fv feature vector inst get fv max location fv num location 1 0 num li++ model label weight classification value line now outside loop over instance fi 0 fi num feature fi++ qeag fi + model label weight 1 0 fl 0 fl fv num location fl++ fli fv index location fl value feature g zero value 1 0 expectation we ll actually add these pre assume feature value zero here we subtract assume model label weight put value zero value feature g qeag fli + math log model label weight math alpha fli + 1 model label weight calculate klgain value klgain num feature klgain incr alpha 0 num i++ j 0 j num feature j++ infinite alpha j alpha alpha j alpha 0 klgain incr alpha p j qeag j alpha alpha 2 gaussian prior variance klgain incr 0 logger info w r n n g klgain incr +i+ +j+ +klgain incr+ alpha +alpha j + feature +ilist get alphabet lookup j + +ilist get target alphabet lookup klgain j + klgain incr logger info klgain length +klgain length j 0 j num feature j++ j % num feature 100 0 0 num i++ logger info +i+ p +ilist get alphabet lookup j + +p j logger info +i+ q +ilist get alphabet lookup j + +q j logger info +i+ alpha +ilist get alphabet lookup j + +alpha j logger info +i+ qeag +ilist get alphabet lookup j + +qeag j logger info klgain +ilist get alphabet lookup j + +klgain j klgain gain instance ilist label vector classification gaussian prior variance ilist get alphabet calc gain ilist classification gaussian prior variance label vector get label vector classification classification label vector ret label vector length 0 length i++ ret get label vector ret gain instance ilist classification classification gaussian prior variance ilist get alphabet calc gain ilist get label vector classification classification gaussian prior variance factory rank feature vector factory label vector classification gaussian prior variance 10 0 factory label vector classification classification classification factory label vector classification gaussian prior variance classification classification gaussian prior variance gaussian prior variance rank feature vector rank feature vector instance ilist ilist get target alphabet classification 0 get alphabet gain ilist classification gaussian prior variance serialization serial u 1 u r r e n t e r l v e r o n 0 write output stream o write u r r e n t e r l v e r o n write classification length 0 classification length i++ write classification read input stream o found read n read classification label vector n 0 n i++ classification label vector read 