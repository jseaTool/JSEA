2005 univ dept part m l l e t m achine learning languag e toolkit 1 0 information see ` l e n e topic zip io format type random parallel topic model runnable task david mimno mc callum worker runnable runnable finish topic assignment start doc num doc num topic topic fit these value encode type topic count count topic pair single topic mask topic bit num type alpha dirichlet alpha alpha over topic alpha sum beta prior topic multinomial over word beta sum e f u l t e t 0 01 smooth mass 0 0 cache coefficient type topic count index feature index topic index topic index topic index dirichlet estimation doc length count histogram document size topic doc count histogram document topic count index topic index position index save build local count random random worker runnable num topic alpha alpha sum beta random random topic assignment type topic count topic start doc num doc num topic num topic num type type topic count length bit count num topic 1 exact power 2 topic mask num topic 1 topic bit bit count topic mask add extra bit topic mask high bit num topic 2 1 topic bit bit count topic mask type topic count type topic count topic topic alpha sum alpha sum alpha alpha beta beta beta sum beta num type random random start doc start doc num doc num doc cache coefficient num topic err worker runnable thread + num topic + topic + topic bit + topic bit + binary topic mask + topic mask there thread we t need go communication overhead ask worker local type topic count call we thread environment thread build local count get topic topic get type topic count type topic count get doc length count doc length count get topic doc count topic doc count initialize alpha statistic size doc length count size topic doc count num topic size collect alpha statistic save reset beta beta beta sum beta beta beta sum beta sum once we sample local count trash global type topic count reuse space build summary type topic count specific worker corpus build local type topic count clear topic total fill topic 0 clear type topic count looking entry first 0 entry type 0 type type topic count length type++ topic count type topic count type position 0 position topic count length topic count position 0 topic count position 0 position++ doc start doc doc size doc start doc + num doc doc++ topic assignment document get doc feature feature document instance get feature topic feature document topic topic topic get feature position 0 position size position++ topic topic position topic parallel topic model u n g n e t o p topic topic ++ format these topic rightmost bit count remain left bit since count high bit sorting desc numeric value guarantee high count lower count type get index position position current type topic count type topic count type start assume empty sort descend here we add count we find location topic we need ensure large left neighbor index 0 current topic current type topic count index topic mask current value current type topic count index 0 current topic topic index++ index current type topic count length overflow type + type current topic current type topic count index topic mask current value current type topic count index topic bit current value 0 value 1 we t worry about sorting topic suffix doesn t matter current type topic count index 1 topic bit + topic current type topic count index current value + 1 topic bit + topic now ensure still sort bubble value up index 0 current type topic count index current type topic count index 1 temp current type topic count index current type topic count index current type topic count index 1 current type topic count index 1 temp index run finish already running finish initialize smooth sampling bucket smooth mass 0 initialize cache coefficient smooth these value selectively replace document zero count topic topic 0 topic num topic topic++ smooth mass + alpha topic beta topic topic + beta sum cache coefficient topic alpha topic topic topic + beta sum doc start doc doc size doc start doc + num doc doc++ doc % 10000 0 processing doc + doc feature feature get doc instance get label topic label get doc topic sample topic doc topic build local count build local type topic count save finish e finish e print stack trace sample topic doc feature feature topic readjust topic stat currently ignore doc topic topic get feature current type topic count type old topic topic topic weight sum doc length get length local topic count num topic local topic index num topic populate topic count position 0 position doc length position++ doc topic position parallel topic model u n g n e t o p local topic count doc topic position ++ build densely list topic zero count dense index 0 topic 0 topic num topic topic++ local topic count topic 0 local topic index dense index topic dense index++ record total zero topic zero topic dense index initialize topic count beta sampling bucket topic beta mass 0 0 initialize cache coefficient topic beta normalize constant dense index 0 dense index zero topic dense index++ topic local topic index dense index n local topic count topic initialize normalization constant n t|d term topic beta mass + beta n topic topic + beta sum update coefficient zero topic cache coefficient topic alpha topic + n topic topic + beta sum topic term mass 0 0 topic term score num topic topic term index topic term value score iterate over position word document position 0 position doc length position++ type get index position position old topic doc topic position current type topic count type topic count type old topic parallel topic model u n g n e t o p count topic normalize constant smooth mass alpha old topic beta topic old topic + beta sum topic beta mass beta local topic count old topic topic old topic + beta sum decrement local doc topic count local topic count old topic maintain dense index we delete old topic local topic count old topic 0 first get dense location old topic dense index 0 we know there somewhere we t need bound check local topic index dense index old topic dense index++ shift remain dense index left dense index zero topic dense index local topic index length 1 local topic index dense index local topic index dense index + 1 dense index++ zero topic decrement global topic count total topic old topic topic old topic 0 old topic + old topic + below 0 add old topic back into normalize constant smooth mass + alpha old topic beta topic old topic + beta sum topic beta mass + beta local topic count old topic topic old topic + beta sum reset cache coefficient topic cache coefficient old topic alpha old topic + local topic count old topic topic old topic + beta sum now go over type topic count decrement appropriate calculate score topic same index 0 current topic current value already decrement old topic parallel topic model u n g n e t o p topic term mass 0 0 index current type topic count length current type topic count index 0 current topic current type topic count index topic mask current value current type topic count index topic bit already decrement current topic old topic we re decrement add up sampling weight same decrement require u reorder topic we re here look cell again current value current value 0 current type topic count index 0 current type topic count index current value topic bit + old topic shift reduce value sub index index sub index current type topic count length 1 current type topic count sub index current type topic count sub index + 1 temp current type topic count sub index current type topic count sub index current type topic count sub index + 1 current type topic count sub index + 1 temp sub index++ already decrement score cache coefficient current topic current value topic term mass + score topic term score index score index++ sample random next uniform smooth mass + topic beta mass + topic term mass orig sample sample sure actually get topic 1 sample topic term mass topic term count++ 1 sample 0 i++ sample topic term score topic current type topic count topic mask current value current type topic count topic bit current type topic count current value + 1 topic bit + topic bubble value up 0 current type topic count current type topic count 1 temp current type topic count current type topic count current type topic count 1 current type topic count 1 temp sample topic term mass sample topic beta mass beta topic count++ sample beta dense index 0 dense index zero topic dense index++ topic local topic index dense index sample local topic count topic topic topic + beta sum sample 0 0 topic topic smooth count++ sample topic beta mass sample beta topic 0 sample alpha topic topic topic + beta sum sample 0 0 topic++ sample alpha topic topic topic + beta sum move position topic first empty position topic word index 0 current type topic count index 0 current type topic count index topic mask topic index++ index current type topic count length err type + type + topic + topic k 0 k current type topic count length k++ err print current type topic count k topic mask + + current type topic count k topic bit + err index now position topic empty cell current type topic count index 0 insert topic guarantee w r t count topic current type topic count index 1 topic bit + topic current value current type topic count index topic bit current type topic count index current value + 1 topic bit + topic bubble increase value left index 0 current type topic count index current type topic count index 1 temp current type topic count index current type topic count index current type topic count index 1 current type topic count index 1 temp index topic 1 err worker runnable sampling + orig sample + + sample + + smooth mass + + topic beta mass + + topic term mass topic num topic 1 t o o appropriate illegal worker runnable topic sample topic 1 put topic into count doc topic position topic smooth mass alpha topic beta topic topic + beta sum topic beta mass beta local topic count topic topic topic + beta sum local topic count topic ++ topic document add topic dense index local topic count topic 1 first find point we insert topic going reason we re keeping track zero topic working backward dense index zero topic dense index 0 local topic index dense index 1 topic local topic index dense index local topic index dense index 1 dense index local topic index dense index topic zero topics++ topic topic ++ update coefficient zero topic cache coefficient topic alpha topic + local topic count topic topic topic + beta sum smooth mass + alpha topic beta topic topic + beta sum topic beta mass + beta local topic count topic topic topic + beta sum save update document topic count histogram dirichlet estimation doc length count doc length ++ dense index 0 dense index zero topic dense index++ topic local topic index dense index topic doc count topic local topic count topic ++ clean up our mess reset coefficient value smooth next doc update zero topic dense index 0 dense index zero topic dense index++ topic local topic index dense index cache coefficient topic alpha topic topic topic + beta sum 