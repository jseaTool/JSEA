topic type io topic inferenc serializable num topic these value encode type topic count count topic pair single topic mask topic bit num type alpha beta beta sum type topic count topic alphabet alphabet random random smooth mass 0 0 cache coefficient topic inferenc type topic count topic alphabet alphabet alpha beta beta sum topic topic type topic count type topic count alphabet alphabet num topic topic length num type type topic count length bit count num topic 1 exact power 2 topic mask num topic 1 topic bit bit count topic mask add extra bit topic mask high bit num topic 2 1 topic bit bit count topic mask alpha alpha beta beta beta sum beta sum cache coefficient num topic topic 0 topic num topic topic++ smooth mass + alpha topic beta topic topic + beta sum cache coefficient topic alpha topic topic topic + beta sum random random random seed seed random random seed gibbs sampling infer topic topic initialize most probable topic zero iteration exactly topic p adjust type topic count p w|t clamp get sample instance instance num iteration thinning burn feature feature instance get doc length size topic doc length local topic count num topic local topic index num topic type current type topic count initialize position most topic type position 0 position doc length position++ type get index position position ignore vocabulary type num type type topic count type length 0 current type topic count type topic count type value topic topic type assign some reason there be type training topic 0 worse random initialization topic position current type topic count 0 topic mask local topic count topic position ++ build densely list topic zero count dense index 0 topic 0 topic num topic topic++ local topic count topic 0 local topic index dense index topic dense index++ record total zero topic zero topic dense index initialize topic count beta sampling bucket topic beta mass 0 0 initialize cache coefficient topic beta normalize constant dense index 0 dense index zero topic dense index++ topic local topic index dense index n local topic count topic initialize normalization constant n t|d term topic beta mass + beta n topic topic + beta sum update coefficient zero topic cache coefficient topic alpha topic + n topic topic + beta sum topic term mass 0 0 topic term score num topic topic term index topic term value score old topic topic num topic sum 0 0 iteration 1 iteration num iteration iteration++ iterate over position word document position 0 position doc length position++ type get index position position ignore vocabulary type num type || type topic count type length 0 old topic topic position current type topic count type topic count type sample adjust count note we need change smooth mass since denominator clamp topic beta mass beta local topic count old topic topic old topic + beta sum decrement local doc topic count local topic count old topic local topic count old topic 0 maintain dense index we delete old topic local topic count old topic 0 first get dense location old topic dense index 0 we know there somewhere we t need bound check local topic index dense index old topic dense index++ shift remain dense index left dense index zero topic dense index local topic index length 1 local topic index dense index local topic index dense index + 1 dense index++ zero topic finish maintain local topic index topic beta mass + beta local topic count old topic topic old topic + beta sum reset cache coefficient topic cache coefficient old topic alpha old topic + local topic count old topic topic old topic + beta sum cache coefficient old topic 0 zero les coefficient + old topic + + alpha old topic + + + local topic count old topic + + topic old topic + + + beta sum + index 0 current topic current value already decrement topic term mass 0 0 index current type topic count length current type topic count index 0 current topic current type topic count index topic mask current value current type topic count index topic bit score cache coefficient current topic current value topic term mass + score topic term score index score index++ sample random next uniform smooth mass + topic beta mass + topic term mass orig sample sample sure actually get topic 1 sample topic term mass topic term count++ 1 sample 0 i++ sample topic term score topic current type topic count topic mask sample topic term mass sample topic beta mass beta topic count++ sample beta dense index 0 dense index zero topic dense index++ topic local topic index dense index sample local topic count topic topic topic + beta sum sample 0 0 topic topic sample topic beta mass sample beta topic 0 sample alpha topic topic topic + beta sum sample 0 0 topic++ topic num topic index 0 index current type topic count length current type topic count index 0 current topic current type topic count index topic mask current value current type topic count index topic bit current topic + + current value + + topic term score index + + cache coefficient current topic index++ sample alpha topic topic topic + beta sum topic position topic topic beta mass beta local topic count topic topic topic + beta sum local topic count topic ++ topic document add topic dense index local topic count topic 1 first find point we insert topic going reason we re keeping track zero topic working backward dense index zero topic dense index 0 local topic index dense index 1 topic local topic index dense index local topic index dense index 1 dense index local topic index dense index topic zero topics++ update coefficient zero topic cache coefficient topic alpha topic + local topic count topic topic topic + beta sum topic beta mass + beta local topic count topic topic topic + beta sum iteration burn iteration burn % thinning 0 save sample topic 0 topic num topic topic++ topic + alpha topic + local topic count topic sum + alpha topic + local topic count topic clean up our mess reset coefficient value smooth next doc update zero topic dense index 0 dense index zero topic dense index++ topic local topic index dense index cache coefficient topic alpha topic topic topic + beta sum sum 0 0 save least sample topic 0 topic num topic topic++ topic alpha topic + local topic count topic sum + topic normalize topic 0 topic num topic topic++ topic sum infer topic instance write distribution instance distribution num iteration total iteration sampling document thinning iteration between save sample burn iteration first save sample threshold proportion topic write max total topic report document write infer distribution instance instance distribution num iteration thinning burn threshold max o print writer print writer distribution print doc name topic proportion sorter sort topic sorter num topic topic 0 topic num topic topic++ initialize sorter dummy value sort topic topic sorter topic topic max 0 || max num topic max num topic doc 0 instance instance instance builder builder builder topic get sample instance num iteration thinning burn builder append doc builder append instance get name builder append instance get name builder append name threshold 0 0 topic 0 topic num topic topic++ sort topic topic topic topic topic sort sort topic 0 max i++ sort topic get weight threshold builder append + sort topic get + + sort topic get weight topic 0 topic num topic topic++ builder append + topic topic builder doc++ close serialization serial u 1 u r r e n t e r l v e r o n 0 n u l l n t e g e r 1 write output stream o write u r r e n t e r l v e r o n write alphabet write num topic write topic mask write topic bit write num type write alpha write beta write beta sum write type topic count write topic write random write smooth mass write cache coefficient read input stream o found read alphabet alphabet read num topic read topic mask read topic bit read num type read alpha read beta read beta sum read type topic count read topic read random random read smooth mass read cache coefficient read topic inferenc read f topic inferenc inferenc input stream ois input stream input stream f inferenc topic inferenc ois read ois close inferenc 