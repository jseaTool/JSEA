collection type feature vector type instance type instance type transducer trainer instance increment train r f stochastic gradient most effective large training set kedarb r f trainer stochastic gradient instance increment r f crf t decay factor lambda some regularization depend training size gaussian prior learning rate t lambda iteration count 0 converge r f factor expectation constraint r f trainer stochastic gradient r f crf instance training sample crf crf expectation r f factor crf constraint r f factor crf learning rate likelihood training sample r f trainer stochastic gradient r f crf learning rate crf crf learning rate learning rate expectation r f factor crf constraint r f factor crf get iteration iteration count transducer get transducer crf finish training converge best learning rate run training sample rate produce maximum increase likelihood accuracy conservative just halve learning rate eta 1 lambda t lambda prior variance num training instance eta 0 t 0 1 lambda eta 0 training step eta 1 lambda t+t 0 t 0 1 2 infinity automatically set learning rate good learning rate likelihood instance training sample num iteration 5 10 akm 1 25 08 best learning rate n e g t v e n f n t y best likelihood change n e g t v e n f n t y curr learning rate 5e 11 curr learning rate 1 curr learning rate 2 crf zero likelihood compute likelihood training sample likelihood change train sample training sample num iteration curr learning rate likelihood likelihood change + likelihood change + learningrate + curr learning rate likelihood change best likelihood change best likelihood change likelihood change best learning rate curr learning rate reset crf zero conservative estimate learning rate best learning rate 2 setting learning rate + best learning rate learning rate best learning rate train sample instance training sample num iteration rate lambda training sample size t 1 lambda rate loglik n e g t v e n f n t y 0 num iteration i++ loglik 0 0 j 0 j training sample size j++ rate 1 lambda t loglik + train incremental likelihood training sample get j rate t + 1 0 loglik compute likelihood instance training sample loglik 0 0 0 training sample size i++ instance training instance training sample get feature vector fv feature vector training instance get label training instance get target loglik + sum lattice crf fv label get total weight loglik sum lattice crf fv get total weight constraint zero expectation zero loglik learning rate r learning rate r get learning rate learning rate train instance training num iteration train training num iteration 1 train instance training num iteration num iteration between evaluation expectation structure match crf constraint structure match crf lambda 1 0 training size t 1 0 lambda learning rate converge training index 0 training size i++ training index add old loglik n e g t v e n f n t y num iteration 0 iteration count++ shuffle index collection shuffle training index loglik 0 0 0 training size i++ learning rate 1 0 lambda t loglik + train incremental likelihood training get training index get t + 1 0 loglikelihood + num iteration + + loglik math ab loglik old loglik 1e 3 converge old loglik loglik runtime get runtime gc iteration count % num iteration between evaluation 0 run evaluator converge t o o add some train batch instance batch membership determine externally? provide some easy create batch train incremental instance training train training 1 train incremental instance training instance expectation structure match crf train incremental likelihood training instance adjust learning rate accord gradient single instance label likelihood train incremental likelihood instance training instance train incremental likelihood training instance learning rate adjust learning rate accord gradient single instance label likelihood train incremental likelihood instance training instance rate single loglik constraint zero expectation zero feature vector fv feature vector training instance get label training instance get target single loglik sum lattice crf fv label constraint incrementor get total weight single loglik sum lattice crf fv expectation incrementor get total weight calculate parameter gradient these instance constraint expectation constraint plus equal expectation 1 change little difference obey weight freeze crf plus equal constraint rate single loglik 