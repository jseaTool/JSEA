2002 univ dept part m l l e t m achine learning languag e toolkit 1 0 information see ` l e n e mc callum optimize logging optimize line optimiz optimize optimizable optimize test test optimizable type matrix ops logger conjugate gradient polak ribiere numeric recipe 10 6 conjugate gradient optimiz logger logger logger get logger conjugate gradient get name converge optimizable gradient value optimizable line optimiz gradient line maximiz step size 1 tolerance 0 0001 gradient tolerance 0 001 max iteration 1000 ep small recitify converging exactly zero function value ep 1 0e 10 optimiz evaluator gradient eval conjugate gradient optimizable gradient value function step size step size step size optimizable function line maximiz back track line search function alternative line maximiz gradient bracket line optimiz function conjugate gradient optimizable gradient value function function 0 01 optimizable get optimizable optimizable converge converge evaluator optimiz evaluator gradient eval eval eval line maximiz line optimiz gradient line maximiz line maximiz line maximiz step size step size step size step size get step size step size get step size step conjugate gradient search fp gg gam dgg step fret xi g h j iteration optimize optimize max iteration tolerance t tolerance t optimize num iteration converge n optimizable get num xi fp optimizable get value xi n g n h n optimizable get value gradient xi arraycopy xi 0 g 0 n arraycopy xi 0 h 0 n step step size iteration 0 iteration count 0 iteration count num iteration iteration count++ logger info conjugate gradient iteration +iterations+ cost +fp step line maximiz optimize xi step fret optimizable get value optimizable get value gradient xi termination numeric recipe 2 0 math ab fret fp tolerance math ab fret + math ab fp +ep logger info conjugate gradient converge old value +fp+ value +fret+ tolerance +tolerance converge fp fret termination mc callum two norm matrix ops two norm xi two norm gradient tolerance logger info conjugate gradient converge gradient two norm + two norm + les + gradient tolerance converge dgg gg 0 0 j 0 j xi length j++ gg + g j g j dgg + xi j xi j g j gam dgg gg j 0 j xi length j++ g j xi j h j xi j + gam h j matrix ops na n h gdruck line search algorithm stop search whenev step found increase value significantly conjugate gradient line maximization find someth close maximum direction test sometime direction suggest g downhill consequently here am setting search direction gradient slope negative 0 matrix ops dot xi h 0 matrix ops xi h logger warning reverting back g matrix ops h xi iterations++ iteration max iteration logger info too many iteration conjugate gradient converge eval eval evaluate optimizable iteration reset xi 