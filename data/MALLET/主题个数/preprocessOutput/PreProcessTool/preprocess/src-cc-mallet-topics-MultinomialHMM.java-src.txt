2005 univ dept part m l l e t m achine learning languag e toolkit 1 0 information see ` l e n e topic type random zip io format gnu trove latent dirichlet allocation david mimno mc callum multinomial h m m num topic topic fit num hide num doc num sequence dirichlet alpha alpha over topic alpha alpha sum prior topic multinomial over word beta beta sum prior transition distribution gamma gamma sum pi sum pi t hash map t hash map document topic document document topic count topic total transition transition total count keep track most time topic document max topic size large document max doc length rath calculate log gamma topic we cache log predictive distribution possible document topic log gamma cache doc log gamma cache num iteration 1000 burnin 200 save sample interval 10 optimize interval 0 show topic interval 50 topic key random random format formatt multinomial h m m topic topic filename num o formatt format get instance formatt maximum fraction digit 5 l h m m + topic document topic t hash map t hash map num topic topic alpha sum topic alpha topic fill alpha alpha sum num topic topic key num topic initializ num doc well load topic topic filename document num doc document num doc max topic num topic max doc length 0 histogram 380 total 0 doc 0 doc num doc doc++ document topic contain key doc t hash map topic count document topic get doc count 0 topic topic count key topic count topic count get topic histogram topic count ++ total + topic count topic count max topic topic max topic topic topic count count + topic count count max doc length max doc length count running total 0 0 337 0 running total + histogram format %d %d % 3f histogram running total total num num count num topic log gamma cache num num topic 0 num state++ topic 0 topic num topic topic++ topic log gamma cache topic max topic topic + 1 topic log gamma cache topic 21 max doc length doc log gamma cache num max doc length + 1 gamma g gamma g num iteration num iteration num iteration num iteration burnin burnin burnin burnin topic interval interval show topic interval interval random seed seed random random seed optimize interval interval optimize interval interval initialize random random random gamma sum gamma num topic count num num topic topic total num transition num num transition total num pi 1000 0 sum pi num pi max 0 total 0 num sequence 0 current 1 cache topic distribution take hashmap mask update distribution topic actually change here we dummy count hash topic t hash map topic dummy t hash map topic 0 topic num topic topic++ topic dummy put topic 1 0 num state++ recache topic topic dummy doc 0 doc num doc doc++ sample doc random recache topic t hash map topic count current topic count topic count current cache topic log gamma cache cache topic topic count key cache current cache topic cache 0 0 0 1 cache length i++ cache cache 1 + math log alpha topic + 1 + current topic count topic doc log gamma cache 0 0 0 1 doc log gamma cache length i++ doc log gamma cache doc log gamma cache 1 + math log alpha sum + 1 + topic total sample o start current milli iteration 1 iteration num iteration iterations++ iteration start current milli print transition doc 0 doc num doc doc++ sample doc random doc % 10000 0 print transition print current milli iteration start + iteration % 10 0 + iteration + print writer print writer buffer writer writer matrix + iteration print transition matrix close print writer buffer writer writer topic + iteration print topic close iteration % 10 0 print writer buffer writer writer + iteration doc 0 doc document length doc++ document doc close flush second math round current milli start 1000 0 minute second 60 second % 60 hour minute 60 minute % 60 day hour 24 hour % 24 print total day 0 print day print day hour 0 print hour print hour minute 0 print minute print minute print second second load topic filename o buffer reader filename end gz buffer reader input stream reader g z p input stream input stream filename buffer reader reader filename num doc 0 line line read line line start field line split doc parse field 0 parse field 1 type parse field 2 topic parse field 4 now add topic document topic contain key doc document topic put doc t hash map document topic get doc contain key topic document topic get doc increment topic document topic get doc put topic 1 doc num doc num doc doc + 1 close load topic + num doc + document load alpha alpha filename o now restore save alpha alpha sum 0 0 buffer reader buffer reader reader alpha filename line line read line line equal field line split \\s+ topic parse field 0 alpha topic 1 0 parse field 1 alpha sum + alpha topic buffer topic key buffer 2 field length i++ topic key append field + topic key topic topic key close load alpha load filename o doc 0 buffer reader buffer reader reader filename line line read line we assume sequence instance parse line document doc additional bookkeeping perform we load m u t load sequence doc++ close load load filename o doc 0 current 1 buffer reader buffer reader reader filename line line read line we assume sequence instance field line split \ parse field 0 document doc current num sequence ++ current doc++ close doc num doc warning document topic + num doc + equal doc + doc + load sample doc random r initialize doc % 10000 0 initialize initialize doc + doc sampling doc + doc start current milli possible document contain word topic entry document topic hash document topic contain key doc t hash map topic count document topic get doc we initialize mode meaningles won t hurt old document doc current topic count topic count old look document feature topic we re initialize mode reduce topic count current old doc length 0 topic topic count key topic count topic count get topic initialize current topic count topic topic count doc length + topic count initialize topic total old doc length recache topic old topic count previou 1 doc 0 previou document doc 1 document doc next 1 initialize doc num doc 1 next document doc+1 log likelihood num sampling num next previou initialize initialize same sampling them we look previou we t decrement count previou start scratch 0 num state++ log likelihood math log count + pi num sequence 1 + sum pi continuation previou document doc 1 0 num state++ log likelihood math log transition previou + gamma infinite log likelihood infinite there four previou next 1 singleton document count old 0 num state++ log likelihood math log count + pi num sequence 1 + sum pi previou 2 beginning count old next document doc+1 transition old next transition old next 0 transition total old 0 num state++ log likelihood math log transition next + gamma count + pi num sequence 1 + sum pi infinite log likelihood infinite beginning next 3 previou document doc 1 transition previou old transition previou old 0 0 num state++ log likelihood math log transition previou + gamma infinite log likelihood infinite 4 middle next document doc+1 transition old next transition old next 0 print transition old + + next transition old next 0 transition total old previou document doc 1 transition previou old transition previou old 0 0 num state++ previou next log likelihood math log transition previou + gamma transition next + 1 + gamma transition total + 1 + gamma sum previou log likelihood math log transition previou + gamma transition next + gamma transition total + 1 + gamma sum log likelihood math log transition previou + gamma transition next + gamma transition total + gamma sum infinite log likelihood infinite middle + doc previou + + + + next transition previou + + transition next + + transition total max n e g t v e n f n t y 0 num state++ log likelihood transition total 10 current topic count topic count current log gamma cache topic log gamma cache total 0 topic topic count key count topic count get topic cache sampling log likelihood + current log gamma cache topic count hybrid count current log gamma cache topic length log likelihood + current log gamma cache topic count current log gamma cache topic length 1 log likelihood + current log gamma cache topic count i++ log likelihood + math log alpha topic + current topic count topic + j 0 j count j++ log likelihood + math log alpha topic + current topic count topic + j alpha sum + topic total + total na n log likelihood na n + alpha topic + + + current topic count topic + + + j + + + alpha sum + + + topic total + + + total total tokens++ cache sampling log likelihood doc log gamma cache doc length hybrid doc length doc log gamma cache length log likelihood doc log gamma cache doc length doc log gamma cache length 1 log likelihood doc log gamma cache doc length i++ log likelihood math log alpha sum + topic total + log likelihood max max log likelihood sum 0 0 0 num state++ na n sampling log likelihood na n sampling sampling math log likelihood max sum + sampling na n sampling log likelihood na n sampling doc % 100 0 sampling r next discrete sampling sum document doc topic 0 topic num topic topic++ topic count topic + topic count get topic topic total + doc length recache topic topic count initialize we re initialize t bother looking next previou count ++ previou document doc 1 transition previou ++ transition total ++ previou next 1 singleton document count ++ previou 2 beginning count ++ next document doc+1 transition next ++ transition total ++ next 3 previou document doc 1 transition previou ++ 4 middle previou document doc 1 transition previou ++ next document doc+1 transition next ++ transition total ++ print transition buffer buffer sorter sort topic sorter num topic 0 num s++ topic 0 topic num topic topic++ sort topic topic sorter topic topic count topic topic total sort sort topic append + + 0 4 i++ topic sort topic get append topic count topic + + topic key topic + append append + count + + num sequence + append + transition total + t 0 t num t++ append t append + transition t + append transition t append transition matrix buffer buffer 0 num s++ t 0 t num t++ append transition t append append topic buffer buffer 0 num s++ topic 0 topic num topic topic++ append topic count topic + append o length 4 err usage multinomial h m m num topic lda lda key metadata exit 0 num topic parse 0 multinomial h m m hmm multinomial h m m num topic 1 150 hmm gamma 1 0 hmm random seed 1 hmm load alpha 2 hmm load 3 hmm initialize hmm sample 